{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader executed\n",
      "Networks defined\n",
      "Loop starting now\n",
      "[0/150][0/8] Loss_D: 1.2884 Loss_G: 14.9014\n",
      "[0/150][1/8] Loss_D: 0.0396 Loss_G: 12.8868\n",
      "[0/150][2/8] Loss_D: 0.0614 Loss_G: 21.8036\n",
      "[0/150][3/8] Loss_D: 0.4924 Loss_G: 0.4253\n",
      "[0/150][4/8] Loss_D: 12.8836 Loss_G: 29.8412\n",
      "[0/150][5/8] Loss_D: 0.4748 Loss_G: 28.8472\n",
      "[0/150][6/8] Loss_D: 1.1916 Loss_G: 23.2354\n",
      "[0/150][7/8] Loss_D: 0.0000 Loss_G: 19.5109\n",
      "[1/150][0/8] Loss_D: 0.0076 Loss_G: 14.8842\n",
      "[1/150][1/8] Loss_D: 0.6951 Loss_G: 19.0559\n",
      "[1/150][2/8] Loss_D: 0.0000 Loss_G: 19.0782\n",
      "[1/150][3/8] Loss_D: 0.0491 Loss_G: 17.2223\n",
      "[1/150][4/8] Loss_D: 0.0001 Loss_G: 14.4326\n",
      "[1/150][5/8] Loss_D: 0.0062 Loss_G: 10.7733\n",
      "[1/150][6/8] Loss_D: 0.0339 Loss_G: 8.2544\n",
      "[1/150][7/8] Loss_D: 0.1943 Loss_G: 10.9990\n",
      "[2/150][0/8] Loss_D: 0.0010 Loss_G: 12.5731\n",
      "[2/150][1/8] Loss_D: 0.0063 Loss_G: 10.9119\n",
      "[2/150][2/8] Loss_D: 0.0430 Loss_G: 12.1104\n",
      "[2/150][3/8] Loss_D: 0.1219 Loss_G: 24.8368\n",
      "[2/150][4/8] Loss_D: 5.1901 Loss_G: 0.0357\n",
      "[2/150][5/8] Loss_D: 16.0997 Loss_G: 26.0915\n",
      "[2/150][6/8] Loss_D: 0.0000 Loss_G: 21.9561\n",
      "[2/150][7/8] Loss_D: 0.0277 Loss_G: 16.7228\n",
      "[3/150][0/8] Loss_D: 0.0805 Loss_G: 12.7226\n",
      "[3/150][1/8] Loss_D: 0.0040 Loss_G: 9.6238\n",
      "[3/150][2/8] Loss_D: 0.3743 Loss_G: 14.8607\n",
      "[3/150][3/8] Loss_D: 0.4812 Loss_G: 12.2197\n",
      "[3/150][4/8] Loss_D: 0.0787 Loss_G: 9.0430\n",
      "[3/150][5/8] Loss_D: 2.3702 Loss_G: 17.8126\n",
      "[3/150][6/8] Loss_D: 0.0206 Loss_G: 20.0113\n",
      "[3/150][7/8] Loss_D: 2.1790 Loss_G: 15.2069\n",
      "[4/150][0/8] Loss_D: 0.0002 Loss_G: 11.8290\n",
      "[4/150][1/8] Loss_D: 0.0016 Loss_G: 8.6340\n",
      "[4/150][2/8] Loss_D: 0.2788 Loss_G: 7.7609\n",
      "[4/150][3/8] Loss_D: 0.9495 Loss_G: 14.3384\n",
      "[4/150][4/8] Loss_D: 0.0027 Loss_G: 11.2082\n",
      "[4/150][5/8] Loss_D: 0.0020 Loss_G: 13.4315\n",
      "[4/150][6/8] Loss_D: 0.0275 Loss_G: 13.7781\n",
      "[4/150][7/8] Loss_D: 0.0036 Loss_G: 8.9475\n",
      "[5/150][0/8] Loss_D: 0.0073 Loss_G: 8.9678\n",
      "[5/150][1/8] Loss_D: 0.0084 Loss_G: 8.0617\n",
      "[5/150][2/8] Loss_D: 0.0076 Loss_G: 8.1545\n",
      "[5/150][3/8] Loss_D: 0.0099 Loss_G: 8.8057\n",
      "[5/150][4/8] Loss_D: 0.0056 Loss_G: 8.8849\n",
      "[5/150][5/8] Loss_D: 0.0083 Loss_G: 7.9633\n",
      "[5/150][6/8] Loss_D: 0.0164 Loss_G: 7.2106\n",
      "[5/150][7/8] Loss_D: 0.0006 Loss_G: 13.0952\n",
      "[6/150][0/8] Loss_D: 0.0015 Loss_G: 14.1093\n",
      "[6/150][1/8] Loss_D: 0.0008 Loss_G: 14.5700\n",
      "[6/150][2/8] Loss_D: 0.0008 Loss_G: 13.9483\n",
      "[6/150][3/8] Loss_D: 0.0007 Loss_G: 14.3765\n",
      "[6/150][4/8] Loss_D: 0.0010 Loss_G: 13.9531\n",
      "[6/150][5/8] Loss_D: 0.0039 Loss_G: 10.2396\n",
      "[6/150][6/8] Loss_D: 0.0020 Loss_G: 10.9328\n",
      "[6/150][7/8] Loss_D: 0.0035 Loss_G: 11.5233\n",
      "[7/150][0/8] Loss_D: 0.0048 Loss_G: 9.6386\n",
      "[7/150][1/8] Loss_D: 0.0045 Loss_G: 9.1686\n",
      "[7/150][2/8] Loss_D: 0.0061 Loss_G: 9.4449\n",
      "[7/150][3/8] Loss_D: 0.0142 Loss_G: 6.2702\n",
      "[7/150][4/8] Loss_D: 0.0172 Loss_G: 6.3094\n",
      "[7/150][5/8] Loss_D: 0.0078 Loss_G: 8.8874\n",
      "[7/150][6/8] Loss_D: 0.0044 Loss_G: 10.1117\n",
      "[7/150][7/8] Loss_D: 0.0058 Loss_G: 8.3665\n",
      "[8/150][0/8] Loss_D: 0.0028 Loss_G: 11.4691\n",
      "[8/150][1/8] Loss_D: 0.0084 Loss_G: 7.1721\n",
      "[8/150][2/8] Loss_D: 0.0089 Loss_G: 8.2870\n",
      "[8/150][3/8] Loss_D: 0.0082 Loss_G: 9.6378\n",
      "[8/150][4/8] Loss_D: 0.0178 Loss_G: 6.8360\n",
      "[8/150][5/8] Loss_D: 0.0150 Loss_G: 9.4223\n",
      "[8/150][6/8] Loss_D: 0.0235 Loss_G: 6.0733\n",
      "[8/150][7/8] Loss_D: 0.0321 Loss_G: 6.6061\n",
      "[9/150][0/8] Loss_D: 0.0209 Loss_G: 7.0984\n",
      "[9/150][1/8] Loss_D: 0.0025 Loss_G: 10.5506\n",
      "[9/150][2/8] Loss_D: 0.0052 Loss_G: 6.9638\n",
      "[9/150][3/8] Loss_D: 0.0078 Loss_G: 6.1726\n",
      "[9/150][4/8] Loss_D: 0.0114 Loss_G: 6.5040\n",
      "[9/150][5/8] Loss_D: 0.0173 Loss_G: 5.7090\n",
      "[9/150][6/8] Loss_D: 0.0257 Loss_G: 5.1105\n",
      "[9/150][7/8] Loss_D: 0.0558 Loss_G: 6.4873\n",
      "[10/150][0/8] Loss_D: 0.0162 Loss_G: 8.3699\n",
      "[10/150][1/8] Loss_D: 0.0105 Loss_G: 6.6265\n",
      "[10/150][2/8] Loss_D: 0.0099 Loss_G: 6.1321\n",
      "[10/150][3/8] Loss_D: 0.0205 Loss_G: 8.1085\n",
      "[10/150][4/8] Loss_D: 0.0141 Loss_G: 7.8630\n",
      "[10/150][5/8] Loss_D: 1.4405 Loss_G: 29.4406\n",
      "[10/150][6/8] Loss_D: 14.5526 Loss_G: 14.8326\n",
      "[10/150][7/8] Loss_D: 0.0132 Loss_G: 11.9011\n",
      "[11/150][0/8] Loss_D: 0.0033 Loss_G: 11.1956\n",
      "[11/150][1/8] Loss_D: 0.0095 Loss_G: 8.8823\n",
      "[11/150][2/8] Loss_D: 0.0375 Loss_G: 8.1720\n",
      "[11/150][3/8] Loss_D: 0.2545 Loss_G: 9.9632\n",
      "[11/150][4/8] Loss_D: 0.0092 Loss_G: 8.7248\n",
      "[11/150][5/8] Loss_D: 0.0150 Loss_G: 9.6423\n",
      "[11/150][6/8] Loss_D: 0.0341 Loss_G: 7.0732\n",
      "[11/150][7/8] Loss_D: 11.2504 Loss_G: 27.5287\n",
      "[12/150][0/8] Loss_D: 23.6046 Loss_G: 18.1497\n",
      "[12/150][1/8] Loss_D: 4.7764 Loss_G: 6.3407\n",
      "[12/150][2/8] Loss_D: 6.0801 Loss_G: 13.9390\n",
      "[12/150][3/8] Loss_D: 0.1491 Loss_G: 12.7262\n",
      "[12/150][4/8] Loss_D: 4.3986 Loss_G: 3.5474\n",
      "[12/150][5/8] Loss_D: 5.8684 Loss_G: 11.0471\n",
      "[12/150][6/8] Loss_D: 5.8344 Loss_G: 3.8696\n",
      "[12/150][7/8] Loss_D: 0.9821 Loss_G: 5.1482\n",
      "[13/150][0/8] Loss_D: 0.4237 Loss_G: 8.5589\n",
      "[13/150][1/8] Loss_D: 0.1162 Loss_G: 7.6425\n",
      "[13/150][2/8] Loss_D: 0.0383 Loss_G: 6.9996\n",
      "[13/150][3/8] Loss_D: 0.1975 Loss_G: 4.7916\n",
      "[13/150][4/8] Loss_D: 0.6310 Loss_G: 6.1313\n",
      "[13/150][5/8] Loss_D: 1.7185 Loss_G: 1.5603\n",
      "[13/150][6/8] Loss_D: 3.7731 Loss_G: 14.3235\n",
      "[13/150][7/8] Loss_D: 2.6323 Loss_G: 9.6789\n",
      "[14/150][0/8] Loss_D: 0.0149 Loss_G: 4.2402\n",
      "[14/150][1/8] Loss_D: 2.2282 Loss_G: 12.2268\n",
      "[14/150][2/8] Loss_D: 0.0523 Loss_G: 14.5595\n",
      "[14/150][3/8] Loss_D: 1.4368 Loss_G: 6.5999\n",
      "[14/150][4/8] Loss_D: 0.0977 Loss_G: 4.6488\n",
      "[14/150][5/8] Loss_D: 0.0514 Loss_G: 5.1938\n",
      "[14/150][6/8] Loss_D: 4.2712 Loss_G: 21.1171\n",
      "[14/150][7/8] Loss_D: 8.3878 Loss_G: 9.2188\n",
      "[15/150][0/8] Loss_D: 0.0160 Loss_G: 1.8883\n",
      "[15/150][1/8] Loss_D: 2.0876 Loss_G: 8.9617\n",
      "[15/150][2/8] Loss_D: 0.9013 Loss_G: 4.4904\n",
      "[15/150][3/8] Loss_D: 0.7232 Loss_G: 6.6262\n",
      "[15/150][4/8] Loss_D: 0.2213 Loss_G: 5.9485\n",
      "[15/150][5/8] Loss_D: 0.1752 Loss_G: 3.5193\n",
      "[15/150][6/8] Loss_D: 0.7206 Loss_G: 11.5485\n",
      "[15/150][7/8] Loss_D: 2.1126 Loss_G: 3.4473\n",
      "[16/150][0/8] Loss_D: 0.8592 Loss_G: 10.0095\n",
      "[16/150][1/8] Loss_D: 0.0386 Loss_G: 10.9963\n",
      "[16/150][2/8] Loss_D: 0.4223 Loss_G: 4.2669\n",
      "[16/150][3/8] Loss_D: 2.0083 Loss_G: 12.5605\n",
      "[16/150][4/8] Loss_D: 0.7063 Loss_G: 10.2843\n",
      "[16/150][5/8] Loss_D: 0.0337 Loss_G: 6.3696\n",
      "[16/150][6/8] Loss_D: 1.1563 Loss_G: 13.0500\n",
      "[16/150][7/8] Loss_D: 3.9715 Loss_G: 5.4521\n",
      "[17/150][0/8] Loss_D: 1.4408 Loss_G: 14.0341\n",
      "[17/150][1/8] Loss_D: 6.2833 Loss_G: 6.1589\n",
      "[17/150][2/8] Loss_D: 1.1491 Loss_G: 9.3487\n",
      "[17/150][3/8] Loss_D: 0.0705 Loss_G: 7.8334\n",
      "[17/150][4/8] Loss_D: 0.7821 Loss_G: 6.1162\n",
      "[17/150][5/8] Loss_D: 1.1874 Loss_G: 0.6969\n",
      "[17/150][6/8] Loss_D: 2.2320 Loss_G: 11.1287\n",
      "[17/150][7/8] Loss_D: 1.4119 Loss_G: 2.1681\n",
      "[18/150][0/8] Loss_D: 3.6654 Loss_G: 13.2661\n",
      "[18/150][1/8] Loss_D: 2.8145 Loss_G: 1.5209\n",
      "[18/150][2/8] Loss_D: 0.0078 Loss_G: 4.3382\n",
      "[18/150][3/8] Loss_D: 0.0025 Loss_G: 7.8072\n",
      "[18/150][4/8] Loss_D: 3.5459 Loss_G: 13.4147\n",
      "[18/150][5/8] Loss_D: 2.5592 Loss_G: 8.9463\n",
      "[18/150][6/8] Loss_D: 0.0858 Loss_G: 2.7838\n",
      "[18/150][7/8] Loss_D: 1.1611 Loss_G: 7.8368\n",
      "[19/150][0/8] Loss_D: 0.9682 Loss_G: 3.8460\n",
      "[19/150][1/8] Loss_D: 3.4477 Loss_G: 12.8347\n",
      "[19/150][2/8] Loss_D: 2.7892 Loss_G: 9.5434\n",
      "[19/150][3/8] Loss_D: 0.0074 Loss_G: 10.5663\n",
      "[19/150][4/8] Loss_D: 0.0106 Loss_G: 9.5503\n",
      "[19/150][5/8] Loss_D: 0.0134 Loss_G: 9.0368\n",
      "[19/150][6/8] Loss_D: 0.0369 Loss_G: 8.2805\n",
      "[19/150][7/8] Loss_D: 0.0353 Loss_G: 7.0228\n",
      "[20/150][0/8] Loss_D: 0.1512 Loss_G: 5.3532\n",
      "[20/150][1/8] Loss_D: 4.6584 Loss_G: 12.9048\n",
      "[20/150][2/8] Loss_D: 15.2824 Loss_G: 8.7227\n",
      "[20/150][3/8] Loss_D: 5.1375 Loss_G: 5.5476\n",
      "[20/150][4/8] Loss_D: 1.4471 Loss_G: 3.3643\n",
      "[20/150][5/8] Loss_D: 0.8673 Loss_G: 2.2810\n",
      "[20/150][6/8] Loss_D: 1.7895 Loss_G: 2.3282\n",
      "[20/150][7/8] Loss_D: 1.4439 Loss_G: 3.6946\n",
      "[21/150][0/8] Loss_D: 0.6318 Loss_G: 5.1770\n",
      "[21/150][1/8] Loss_D: 0.6563 Loss_G: 4.8775\n",
      "[21/150][2/8] Loss_D: 0.8211 Loss_G: 3.7662\n",
      "[21/150][3/8] Loss_D: 0.8202 Loss_G: 3.2798\n",
      "[21/150][4/8] Loss_D: 1.2892 Loss_G: 3.1089\n",
      "[21/150][5/8] Loss_D: 1.1759 Loss_G: 0.4056\n",
      "[21/150][6/8] Loss_D: 2.9117 Loss_G: 7.4808\n",
      "[21/150][7/8] Loss_D: 3.3595 Loss_G: 0.8980\n",
      "[22/150][0/8] Loss_D: 2.1765 Loss_G: 5.4192\n",
      "[22/150][1/8] Loss_D: 2.5166 Loss_G: 0.8222\n",
      "[22/150][2/8] Loss_D: 1.5253 Loss_G: 6.0061\n",
      "[22/150][3/8] Loss_D: 1.5362 Loss_G: 0.3349\n",
      "[22/150][4/8] Loss_D: 2.2555 Loss_G: 6.0313\n",
      "[22/150][5/8] Loss_D: 1.3529 Loss_G: 2.3799\n",
      "[22/150][6/8] Loss_D: 1.3637 Loss_G: 2.8226\n",
      "[22/150][7/8] Loss_D: 0.8312 Loss_G: 4.4045\n",
      "[23/150][0/8] Loss_D: 1.4901 Loss_G: 0.8711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23/150][1/8] Loss_D: 1.6451 Loss_G: 11.2204\n",
      "[23/150][2/8] Loss_D: 8.7095 Loss_G: 1.5905\n",
      "[23/150][3/8] Loss_D: 0.8573 Loss_G: 0.8994\n",
      "[23/150][4/8] Loss_D: 1.0390 Loss_G: 3.5491\n",
      "[23/150][5/8] Loss_D: 1.8526 Loss_G: 0.2149\n",
      "[23/150][6/8] Loss_D: 2.4080 Loss_G: 3.2354\n",
      "[23/150][7/8] Loss_D: 1.1055 Loss_G: 0.9353\n",
      "[24/150][0/8] Loss_D: 1.1599 Loss_G: 4.1118\n",
      "[24/150][1/8] Loss_D: 1.3554 Loss_G: 0.3682\n",
      "[24/150][2/8] Loss_D: 2.8933 Loss_G: 5.8726\n",
      "[24/150][3/8] Loss_D: 3.1503 Loss_G: 1.9187\n",
      "[24/150][4/8] Loss_D: 1.0201 Loss_G: 1.9925\n",
      "[24/150][5/8] Loss_D: 0.8600 Loss_G: 3.1200\n",
      "[24/150][6/8] Loss_D: 1.0880 Loss_G: 0.6771\n",
      "[24/150][7/8] Loss_D: 1.5225 Loss_G: 4.6954\n",
      "[25/150][0/8] Loss_D: 1.7471 Loss_G: 2.3219\n",
      "[25/150][1/8] Loss_D: 1.0954 Loss_G: 3.2186\n",
      "[25/150][2/8] Loss_D: 0.4421 Loss_G: 2.9021\n",
      "[25/150][3/8] Loss_D: 0.4382 Loss_G: 2.7229\n",
      "[25/150][4/8] Loss_D: 0.6129 Loss_G: 5.5702\n",
      "[25/150][5/8] Loss_D: 2.6958 Loss_G: 1.2058\n",
      "[25/150][6/8] Loss_D: 1.8214 Loss_G: 5.3441\n",
      "[25/150][7/8] Loss_D: 3.8665 Loss_G: 0.0037\n",
      "[26/150][0/8] Loss_D: 5.1788 Loss_G: 1.8482\n",
      "[26/150][1/8] Loss_D: 1.0465 Loss_G: 4.7578\n",
      "[26/150][2/8] Loss_D: 3.7434 Loss_G: 0.3994\n",
      "[26/150][3/8] Loss_D: 3.2831 Loss_G: 2.9416\n",
      "[26/150][4/8] Loss_D: 2.2212 Loss_G: 0.5589\n",
      "[26/150][5/8] Loss_D: 1.8327 Loss_G: 3.6761\n",
      "[26/150][6/8] Loss_D: 1.8554 Loss_G: 0.9477\n",
      "[26/150][7/8] Loss_D: 1.1832 Loss_G: 2.0919\n",
      "[27/150][0/8] Loss_D: 0.9048 Loss_G: 1.9660\n",
      "[27/150][1/8] Loss_D: 0.9602 Loss_G: 1.3120\n",
      "[27/150][2/8] Loss_D: 0.7861 Loss_G: 3.5871\n",
      "[27/150][3/8] Loss_D: 1.2537 Loss_G: 0.3489\n",
      "[27/150][4/8] Loss_D: 2.5107 Loss_G: 4.3211\n",
      "[27/150][5/8] Loss_D: 2.5590 Loss_G: 0.8026\n",
      "[27/150][6/8] Loss_D: 1.3980 Loss_G: 2.9843\n",
      "[27/150][7/8] Loss_D: 1.1397 Loss_G: 0.7784\n",
      "[28/150][0/8] Loss_D: 2.0562 Loss_G: 4.4609\n",
      "[28/150][1/8] Loss_D: 3.3165 Loss_G: 0.4476\n",
      "[28/150][2/8] Loss_D: 1.9580 Loss_G: 1.8189\n",
      "[28/150][3/8] Loss_D: 1.6045 Loss_G: 0.8406\n",
      "[28/150][4/8] Loss_D: 1.3330 Loss_G: 2.2637\n",
      "[28/150][5/8] Loss_D: 1.1986 Loss_G: 0.5586\n",
      "[28/150][6/8] Loss_D: 1.5711 Loss_G: 4.4764\n",
      "[28/150][7/8] Loss_D: 2.0321 Loss_G: 0.4791\n",
      "[29/150][0/8] Loss_D: 1.6981 Loss_G: 2.3120\n",
      "[29/150][1/8] Loss_D: 1.2866 Loss_G: 0.8349\n",
      "[29/150][2/8] Loss_D: 1.1407 Loss_G: 1.9589\n",
      "[29/150][3/8] Loss_D: 0.9814 Loss_G: 0.7953\n",
      "[29/150][4/8] Loss_D: 1.0670 Loss_G: 2.6553\n",
      "[29/150][5/8] Loss_D: 1.0428 Loss_G: 0.9562\n",
      "[29/150][6/8] Loss_D: 0.6166 Loss_G: 2.2969\n",
      "[29/150][7/8] Loss_D: 0.5884 Loss_G: 3.3130\n",
      "[30/150][0/8] Loss_D: 0.7257 Loss_G: 0.7716\n",
      "[30/150][1/8] Loss_D: 1.2063 Loss_G: 3.5661\n",
      "[30/150][2/8] Loss_D: 1.1577 Loss_G: 0.7868\n",
      "[30/150][3/8] Loss_D: 1.3429 Loss_G: 3.4964\n",
      "[30/150][4/8] Loss_D: 0.9971 Loss_G: 0.9418\n",
      "[30/150][5/8] Loss_D: 1.2184 Loss_G: 2.9127\n",
      "[30/150][6/8] Loss_D: 1.2486 Loss_G: 0.7378\n",
      "[30/150][7/8] Loss_D: 2.0788 Loss_G: 6.3584\n",
      "[31/150][0/8] Loss_D: 2.4787 Loss_G: 0.4660\n",
      "[31/150][1/8] Loss_D: 1.1894 Loss_G: 3.1270\n",
      "[31/150][2/8] Loss_D: 1.2845 Loss_G: 1.0679\n",
      "[31/150][3/8] Loss_D: 1.5402 Loss_G: 3.9400\n",
      "[31/150][4/8] Loss_D: 2.7021 Loss_G: 0.1457\n",
      "[31/150][5/8] Loss_D: 2.3125 Loss_G: 2.7278\n",
      "[31/150][6/8] Loss_D: 2.1040 Loss_G: 0.6581\n",
      "[31/150][7/8] Loss_D: 1.4184 Loss_G: 1.1424\n",
      "[32/150][0/8] Loss_D: 1.0757 Loss_G: 1.2923\n",
      "[32/150][1/8] Loss_D: 1.0271 Loss_G: 1.0447\n",
      "[32/150][2/8] Loss_D: 1.0235 Loss_G: 1.6984\n",
      "[32/150][3/8] Loss_D: 1.0198 Loss_G: 0.9033\n",
      "[32/150][4/8] Loss_D: 1.0829 Loss_G: 2.6552\n",
      "[32/150][5/8] Loss_D: 1.5774 Loss_G: 0.3146\n",
      "[32/150][6/8] Loss_D: 1.9325 Loss_G: 1.9868\n",
      "[32/150][7/8] Loss_D: 1.1664 Loss_G: 0.9638\n",
      "[33/150][0/8] Loss_D: 0.9659 Loss_G: 1.8026\n",
      "[33/150][1/8] Loss_D: 0.9045 Loss_G: 0.9659\n",
      "[33/150][2/8] Loss_D: 1.2578 Loss_G: 4.4323\n",
      "[33/150][3/8] Loss_D: 3.1487 Loss_G: 0.6782\n",
      "[33/150][4/8] Loss_D: 1.1397 Loss_G: 0.9046\n",
      "[33/150][5/8] Loss_D: 0.9112 Loss_G: 2.3196\n",
      "[33/150][6/8] Loss_D: 1.0216 Loss_G: 0.9119\n",
      "[33/150][7/8] Loss_D: 1.0188 Loss_G: 3.5369\n",
      "[34/150][0/8] Loss_D: 1.1839 Loss_G: 1.7989\n",
      "[34/150][1/8] Loss_D: 0.3767 Loss_G: 1.6074\n",
      "[34/150][2/8] Loss_D: 0.6749 Loss_G: 3.1378\n",
      "[34/150][3/8] Loss_D: 0.3999 Loss_G: 4.4637\n",
      "[34/150][4/8] Loss_D: 1.1822 Loss_G: 0.0558\n",
      "[34/150][5/8] Loss_D: 3.0947 Loss_G: 12.1641\n",
      "[34/150][6/8] Loss_D: 8.3066 Loss_G: 0.2246\n",
      "[34/150][7/8] Loss_D: 2.8766 Loss_G: 5.4064\n",
      "[35/150][0/8] Loss_D: 3.7261 Loss_G: 1.4312\n",
      "[35/150][1/8] Loss_D: 0.5743 Loss_G: 1.3374\n",
      "[35/150][2/8] Loss_D: 0.6238 Loss_G: 4.3200\n",
      "[35/150][3/8] Loss_D: 0.6774 Loss_G: 1.8567\n",
      "[35/150][4/8] Loss_D: 0.5967 Loss_G: 3.4018\n",
      "[35/150][5/8] Loss_D: 0.4777 Loss_G: 2.9148\n",
      "[35/150][6/8] Loss_D: 1.1512 Loss_G: 4.0107\n",
      "[35/150][7/8] Loss_D: 2.1156 Loss_G: 0.0762\n",
      "[36/150][0/8] Loss_D: 3.1995 Loss_G: 4.1379\n",
      "[36/150][1/8] Loss_D: 2.4567 Loss_G: 0.2869\n",
      "[36/150][2/8] Loss_D: 1.9687 Loss_G: 3.6702\n",
      "[36/150][3/8] Loss_D: 1.7724 Loss_G: 0.4907\n",
      "[36/150][4/8] Loss_D: 1.6817 Loss_G: 3.3833\n",
      "[36/150][5/8] Loss_D: 1.7250 Loss_G: 0.3785\n",
      "[36/150][6/8] Loss_D: 1.6720 Loss_G: 3.5420\n",
      "[36/150][7/8] Loss_D: 1.8024 Loss_G: 0.2566\n",
      "[37/150][0/8] Loss_D: 1.9458 Loss_G: 3.4618\n",
      "[37/150][1/8] Loss_D: 1.8368 Loss_G: 0.2804\n",
      "[37/150][2/8] Loss_D: 1.9433 Loss_G: 3.1477\n",
      "[37/150][3/8] Loss_D: 1.6878 Loss_G: 0.3795\n",
      "[37/150][4/8] Loss_D: 1.7049 Loss_G: 2.4529\n",
      "[37/150][5/8] Loss_D: 1.6357 Loss_G: 0.3599\n",
      "[37/150][6/8] Loss_D: 1.6871 Loss_G: 2.5135\n",
      "[37/150][7/8] Loss_D: 1.6376 Loss_G: 0.4054\n",
      "[38/150][0/8] Loss_D: 1.5479 Loss_G: 2.5047\n",
      "[38/150][1/8] Loss_D: 1.5311 Loss_G: 0.3390\n",
      "[38/150][2/8] Loss_D: 1.8203 Loss_G: 2.3106\n",
      "[38/150][3/8] Loss_D: 1.9554 Loss_G: 0.2934\n",
      "[38/150][4/8] Loss_D: 1.7620 Loss_G: 1.8601\n",
      "[38/150][5/8] Loss_D: 1.4906 Loss_G: 0.5495\n",
      "[38/150][6/8] Loss_D: 1.2808 Loss_G: 1.5428\n",
      "[38/150][7/8] Loss_D: 1.3018 Loss_G: 0.5454\n",
      "[39/150][0/8] Loss_D: 1.2511 Loss_G: 1.8167\n",
      "[39/150][1/8] Loss_D: 1.2907 Loss_G: 0.4632\n",
      "[39/150][2/8] Loss_D: 1.3335 Loss_G: 2.3308\n",
      "[39/150][3/8] Loss_D: 1.4847 Loss_G: 0.3646\n",
      "[39/150][4/8] Loss_D: 1.5319 Loss_G: 2.1923\n",
      "[39/150][5/8] Loss_D: 1.4453 Loss_G: 0.4444\n",
      "[39/150][6/8] Loss_D: 1.3568 Loss_G: 2.0949\n",
      "[39/150][7/8] Loss_D: 1.3810 Loss_G: 0.4786\n",
      "[40/150][0/8] Loss_D: 1.4429 Loss_G: 2.9298\n",
      "[40/150][1/8] Loss_D: 2.2330 Loss_G: 0.3410\n",
      "[40/150][2/8] Loss_D: 1.4762 Loss_G: 2.1003\n",
      "[40/150][3/8] Loss_D: 1.7029 Loss_G: 0.2759\n",
      "[40/150][4/8] Loss_D: 1.6293 Loss_G: 2.0361\n",
      "[40/150][5/8] Loss_D: 1.4760 Loss_G: 0.3978\n",
      "[40/150][6/8] Loss_D: 1.6012 Loss_G: 2.4737\n",
      "[40/150][7/8] Loss_D: 1.8974 Loss_G: 0.2507\n",
      "[41/150][0/8] Loss_D: 1.7409 Loss_G: 2.0859\n",
      "[41/150][1/8] Loss_D: 1.4823 Loss_G: 0.5175\n",
      "[41/150][2/8] Loss_D: 1.3792 Loss_G: 1.7040\n",
      "[41/150][3/8] Loss_D: 1.3995 Loss_G: 0.4713\n",
      "[41/150][4/8] Loss_D: 1.4207 Loss_G: 1.6295\n",
      "[41/150][5/8] Loss_D: 1.3382 Loss_G: 0.5590\n",
      "[41/150][6/8] Loss_D: 1.2112 Loss_G: 1.7374\n",
      "[41/150][7/8] Loss_D: 1.0978 Loss_G: 0.6981\n",
      "[42/150][0/8] Loss_D: 1.2029 Loss_G: 1.9904\n",
      "[42/150][1/8] Loss_D: 1.4422 Loss_G: 0.2773\n",
      "[42/150][2/8] Loss_D: 1.7161 Loss_G: 2.5645\n",
      "[42/150][3/8] Loss_D: 1.8841 Loss_G: 0.3626\n",
      "[42/150][4/8] Loss_D: 1.5176 Loss_G: 1.7218\n",
      "[42/150][5/8] Loss_D: 1.2798 Loss_G: 0.6303\n",
      "[42/150][6/8] Loss_D: 1.2282 Loss_G: 1.6349\n",
      "[42/150][7/8] Loss_D: 1.2307 Loss_G: 0.5907\n",
      "[43/150][0/8] Loss_D: 1.2048 Loss_G: 2.0616\n",
      "[43/150][1/8] Loss_D: 1.2406 Loss_G: 0.4769\n",
      "[43/150][2/8] Loss_D: 1.3235 Loss_G: 2.0574\n",
      "[43/150][3/8] Loss_D: 1.2830 Loss_G: 0.4915\n",
      "[43/150][4/8] Loss_D: 1.2208 Loss_G: 2.1079\n",
      "[43/150][5/8] Loss_D: 1.1612 Loss_G: 0.6338\n",
      "[43/150][6/8] Loss_D: 1.1089 Loss_G: 1.9222\n",
      "[43/150][7/8] Loss_D: 1.0738 Loss_G: 0.6370\n",
      "[44/150][0/8] Loss_D: 1.2964 Loss_G: 2.4533\n",
      "[44/150][1/8] Loss_D: 1.6931 Loss_G: 0.2650\n",
      "[44/150][2/8] Loss_D: 1.7224 Loss_G: 2.2430\n",
      "[44/150][3/8] Loss_D: 1.4325 Loss_G: 0.4634\n",
      "[44/150][4/8] Loss_D: 1.4457 Loss_G: 2.2858\n",
      "[44/150][5/8] Loss_D: 1.4867 Loss_G: 0.5299\n",
      "[44/150][6/8] Loss_D: 1.3322 Loss_G: 1.9216\n",
      "[44/150][7/8] Loss_D: 1.3493 Loss_G: 0.5472\n",
      "[45/150][0/8] Loss_D: 1.2220 Loss_G: 1.8333\n",
      "[45/150][1/8] Loss_D: 1.1919 Loss_G: 0.5525\n",
      "[45/150][2/8] Loss_D: 1.2940 Loss_G: 2.1756\n",
      "[45/150][3/8] Loss_D: 1.4759 Loss_G: 0.3693\n",
      "[45/150][4/8] Loss_D: 1.4671 Loss_G: 2.1424\n",
      "[45/150][5/8] Loss_D: 1.4133 Loss_G: 0.4496\n",
      "[45/150][6/8] Loss_D: 1.2630 Loss_G: 2.2148\n",
      "[45/150][7/8] Loss_D: 1.4407 Loss_G: 0.3920\n",
      "[46/150][0/8] Loss_D: 1.4987 Loss_G: 2.5756\n",
      "[46/150][1/8] Loss_D: 1.7001 Loss_G: 0.4265\n",
      "[46/150][2/8] Loss_D: 1.4192 Loss_G: 2.4203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46/150][3/8] Loss_D: 1.5589 Loss_G: 0.3391\n",
      "[46/150][4/8] Loss_D: 1.6323 Loss_G: 2.2866\n",
      "[46/150][5/8] Loss_D: 1.6170 Loss_G: 0.4514\n",
      "[46/150][6/8] Loss_D: 1.1839 Loss_G: 1.7729\n",
      "[46/150][7/8] Loss_D: 1.1301 Loss_G: 1.0616\n",
      "[47/150][0/8] Loss_D: 1.0161 Loss_G: 1.0160\n",
      "[47/150][1/8] Loss_D: 1.1493 Loss_G: 1.4986\n",
      "[47/150][2/8] Loss_D: 1.2332 Loss_G: 0.3928\n",
      "[47/150][3/8] Loss_D: 1.4580 Loss_G: 3.1927\n",
      "[47/150][4/8] Loss_D: 2.0864 Loss_G: 0.2704\n",
      "[47/150][5/8] Loss_D: 1.5497 Loss_G: 2.0573\n",
      "[47/150][6/8] Loss_D: 1.2208 Loss_G: 0.6604\n",
      "[47/150][7/8] Loss_D: 1.1927 Loss_G: 2.4120\n",
      "[48/150][0/8] Loss_D: 1.1947 Loss_G: 0.6201\n",
      "[48/150][1/8] Loss_D: 0.6577 Loss_G: 2.3775\n",
      "[48/150][2/8] Loss_D: 0.7048 Loss_G: 2.9325\n",
      "[48/150][3/8] Loss_D: 0.9087 Loss_G: 1.3428\n",
      "[48/150][4/8] Loss_D: 1.4639 Loss_G: 4.5918\n",
      "[48/150][5/8] Loss_D: 2.3796 Loss_G: 0.3831\n",
      "[48/150][6/8] Loss_D: 1.9269 Loss_G: 3.4321\n",
      "[48/150][7/8] Loss_D: 1.7906 Loss_G: 0.5791\n",
      "[49/150][0/8] Loss_D: 1.6314 Loss_G: 2.6968\n",
      "[49/150][1/8] Loss_D: 1.4041 Loss_G: 0.8221\n",
      "[49/150][2/8] Loss_D: 1.1843 Loss_G: 2.0724\n",
      "[49/150][3/8] Loss_D: 1.0162 Loss_G: 0.8466\n",
      "[49/150][4/8] Loss_D: 1.1800 Loss_G: 3.6070\n",
      "[49/150][5/8] Loss_D: 1.9288 Loss_G: 0.6768\n",
      "[49/150][6/8] Loss_D: 1.1856 Loss_G: 2.9811\n",
      "[49/150][7/8] Loss_D: 2.1423 Loss_G: 0.1437\n",
      "[50/150][0/8] Loss_D: 1.9726 Loss_G: 3.3519\n",
      "[50/150][1/8] Loss_D: 1.1095 Loss_G: 0.7015\n",
      "[50/150][2/8] Loss_D: 1.3540 Loss_G: 2.5153\n",
      "[50/150][3/8] Loss_D: 1.3496 Loss_G: 0.7203\n",
      "[50/150][4/8] Loss_D: 1.6393 Loss_G: 3.7337\n",
      "[50/150][5/8] Loss_D: 1.0953 Loss_G: 3.1085\n",
      "[50/150][6/8] Loss_D: 0.7585 Loss_G: 0.5680\n",
      "[50/150][7/8] Loss_D: 1.7488 Loss_G: 2.7950\n",
      "[51/150][0/8] Loss_D: 0.9341 Loss_G: 2.5239\n",
      "[51/150][1/8] Loss_D: 0.7696 Loss_G: 4.1429\n",
      "[51/150][2/8] Loss_D: 0.9935 Loss_G: 1.0289\n",
      "[51/150][3/8] Loss_D: 1.0081 Loss_G: 4.3706\n",
      "[51/150][4/8] Loss_D: 0.6335 Loss_G: 3.5465\n",
      "[51/150][5/8] Loss_D: 0.2362 Loss_G: 2.8387\n",
      "[51/150][6/8] Loss_D: 0.2535 Loss_G: 2.6347\n",
      "[51/150][7/8] Loss_D: 0.3058 Loss_G: 2.4506\n",
      "[52/150][0/8] Loss_D: 0.3158 Loss_G: 3.1622\n",
      "[52/150][1/8] Loss_D: 0.4397 Loss_G: 2.5597\n",
      "[52/150][2/8] Loss_D: 1.7769 Loss_G: 5.6899\n",
      "[52/150][3/8] Loss_D: 3.0036 Loss_G: 1.3404\n",
      "[52/150][4/8] Loss_D: 0.9974 Loss_G: 1.9049\n",
      "[52/150][5/8] Loss_D: 0.7953 Loss_G: 2.1354\n",
      "[52/150][6/8] Loss_D: 0.9542 Loss_G: 1.8615\n",
      "[52/150][7/8] Loss_D: 1.0125 Loss_G: 1.6622\n",
      "[53/150][0/8] Loss_D: 0.6783 Loss_G: 2.1805\n",
      "[53/150][1/8] Loss_D: 0.7772 Loss_G: 5.2292\n",
      "[53/150][2/8] Loss_D: 2.7831 Loss_G: 0.0340\n",
      "[53/150][3/8] Loss_D: 3.2526 Loss_G: 3.4740\n",
      "[53/150][4/8] Loss_D: 2.0034 Loss_G: 0.6669\n",
      "[53/150][5/8] Loss_D: 1.5361 Loss_G: 2.4391\n",
      "[53/150][6/8] Loss_D: 1.1976 Loss_G: 0.9047\n",
      "[53/150][7/8] Loss_D: 1.2023 Loss_G: 1.7136\n",
      "[54/150][0/8] Loss_D: 1.1095 Loss_G: 0.9564\n",
      "[54/150][1/8] Loss_D: 1.1960 Loss_G: 2.1325\n",
      "[54/150][2/8] Loss_D: 1.3729 Loss_G: 0.4335\n",
      "[54/150][3/8] Loss_D: 1.4189 Loss_G: 2.6219\n",
      "[54/150][4/8] Loss_D: 1.5255 Loss_G: 0.3339\n",
      "[54/150][5/8] Loss_D: 1.6843 Loss_G: 2.5626\n",
      "[54/150][6/8] Loss_D: 1.4820 Loss_G: 0.6369\n",
      "[54/150][7/8] Loss_D: 1.3595 Loss_G: 1.9662\n",
      "[55/150][0/8] Loss_D: 1.2844 Loss_G: 0.6702\n",
      "[55/150][1/8] Loss_D: 1.2434 Loss_G: 2.0198\n",
      "[55/150][2/8] Loss_D: 1.3158 Loss_G: 0.5097\n",
      "[55/150][3/8] Loss_D: 1.4008 Loss_G: 3.4870\n",
      "[55/150][4/8] Loss_D: 1.7426 Loss_G: 0.5595\n",
      "[55/150][5/8] Loss_D: 1.1187 Loss_G: 3.5553\n",
      "[55/150][6/8] Loss_D: 0.8405 Loss_G: 1.3444\n",
      "[55/150][7/8] Loss_D: 0.4892 Loss_G: 3.0447\n",
      "[56/150][0/8] Loss_D: 0.1451 Loss_G: 3.9264\n",
      "[56/150][1/8] Loss_D: 0.4683 Loss_G: 4.2152\n",
      "[56/150][2/8] Loss_D: 0.4856 Loss_G: 4.1396\n",
      "[56/150][3/8] Loss_D: 0.8178 Loss_G: 6.0347\n",
      "[56/150][4/8] Loss_D: 2.2748 Loss_G: 2.2501\n",
      "[56/150][5/8] Loss_D: 0.6796 Loss_G: 3.7595\n",
      "[56/150][6/8] Loss_D: 0.4466 Loss_G: 3.3566\n",
      "[56/150][7/8] Loss_D: 0.5514 Loss_G: 3.5846\n",
      "[57/150][0/8] Loss_D: 0.7597 Loss_G: 2.6129\n",
      "[57/150][1/8] Loss_D: 0.7486 Loss_G: 3.3152\n",
      "[57/150][2/8] Loss_D: 1.1345 Loss_G: 1.3510\n",
      "[57/150][3/8] Loss_D: 1.4074 Loss_G: 8.7927\n",
      "[57/150][4/8] Loss_D: 7.1190 Loss_G: 1.2107\n",
      "[57/150][5/8] Loss_D: 0.9139 Loss_G: 0.6894\n",
      "[57/150][6/8] Loss_D: 1.4299 Loss_G: 3.5352\n",
      "[57/150][7/8] Loss_D: 2.3786 Loss_G: 0.2799\n",
      "[58/150][0/8] Loss_D: 1.5554 Loss_G: 2.9095\n",
      "[58/150][1/8] Loss_D: 0.9636 Loss_G: 1.3628\n",
      "[58/150][2/8] Loss_D: 0.8650 Loss_G: 1.3703\n",
      "[58/150][3/8] Loss_D: 0.8988 Loss_G: 1.6693\n",
      "[58/150][4/8] Loss_D: 0.9389 Loss_G: 1.1964\n",
      "[58/150][5/8] Loss_D: 1.0270 Loss_G: 1.7012\n",
      "[58/150][6/8] Loss_D: 1.0178 Loss_G: 0.6923\n",
      "[58/150][7/8] Loss_D: 1.6381 Loss_G: 4.0083\n",
      "[59/150][0/8] Loss_D: 3.0803 Loss_G: 0.5891\n",
      "[59/150][1/8] Loss_D: 1.5514 Loss_G: 2.6235\n",
      "[59/150][2/8] Loss_D: 1.7321 Loss_G: 0.3568\n",
      "[59/150][3/8] Loss_D: 1.2560 Loss_G: 2.5826\n",
      "[59/150][4/8] Loss_D: 0.9825 Loss_G: 2.4012\n",
      "[59/150][5/8] Loss_D: 1.2837 Loss_G: 1.0420\n",
      "[59/150][6/8] Loss_D: 1.6653 Loss_G: 4.6211\n",
      "[59/150][7/8] Loss_D: 2.9207 Loss_G: 0.6763\n",
      "[60/150][0/8] Loss_D: 0.7673 Loss_G: 2.0386\n",
      "[60/150][1/8] Loss_D: 0.8972 Loss_G: 2.7022\n",
      "[60/150][2/8] Loss_D: 1.5718 Loss_G: 0.2107\n",
      "[60/150][3/8] Loss_D: 1.7646 Loss_G: 4.1021\n",
      "[60/150][4/8] Loss_D: 1.6481 Loss_G: 0.8245\n",
      "[60/150][5/8] Loss_D: 0.8113 Loss_G: 2.0496\n",
      "[60/150][6/8] Loss_D: 0.4992 Loss_G: 2.5503\n",
      "[60/150][7/8] Loss_D: 0.5556 Loss_G: 1.7713\n",
      "[61/150][0/8] Loss_D: 1.1644 Loss_G: 3.5127\n",
      "[61/150][1/8] Loss_D: 1.7414 Loss_G: 0.2737\n",
      "[61/150][2/8] Loss_D: 1.6735 Loss_G: 3.8663\n",
      "[61/150][3/8] Loss_D: 1.4905 Loss_G: 1.3446\n",
      "[61/150][4/8] Loss_D: 0.8752 Loss_G: 3.0299\n",
      "[61/150][5/8] Loss_D: 0.8262 Loss_G: 2.2334\n",
      "[61/150][6/8] Loss_D: 0.9894 Loss_G: 0.5071\n",
      "[61/150][7/8] Loss_D: 1.7357 Loss_G: 5.0982\n",
      "[62/150][0/8] Loss_D: 2.2160 Loss_G: 0.7733\n",
      "[62/150][1/8] Loss_D: 0.8623 Loss_G: 2.2082\n",
      "[62/150][2/8] Loss_D: 0.8067 Loss_G: 3.4263\n",
      "[62/150][3/8] Loss_D: 1.7887 Loss_G: 0.2985\n",
      "[62/150][4/8] Loss_D: 1.4933 Loss_G: 5.6059\n",
      "[62/150][5/8] Loss_D: 1.7017 Loss_G: 1.2345\n",
      "[62/150][6/8] Loss_D: 0.2880 Loss_G: 1.7768\n",
      "[62/150][7/8] Loss_D: 0.7398 Loss_G: 4.2562\n",
      "[63/150][0/8] Loss_D: 0.7923 Loss_G: 1.4284\n",
      "[63/150][1/8] Loss_D: 0.9276 Loss_G: 4.3503\n",
      "[63/150][2/8] Loss_D: 0.7280 Loss_G: 1.7629\n",
      "[63/150][3/8] Loss_D: 2.1790 Loss_G: 3.5481\n",
      "[63/150][4/8] Loss_D: 2.0200 Loss_G: 0.8610\n",
      "[63/150][5/8] Loss_D: 1.4863 Loss_G: 3.6737\n",
      "[63/150][6/8] Loss_D: 1.6241 Loss_G: 0.6026\n",
      "[63/150][7/8] Loss_D: 1.6017 Loss_G: 4.5090\n",
      "[64/150][0/8] Loss_D: 2.2970 Loss_G: 0.4222\n",
      "[64/150][1/8] Loss_D: 0.9482 Loss_G: 4.3614\n",
      "[64/150][2/8] Loss_D: 0.5365 Loss_G: 2.0946\n",
      "[64/150][3/8] Loss_D: 0.3896 Loss_G: 2.0635\n",
      "[64/150][4/8] Loss_D: 0.4343 Loss_G: 2.3548\n",
      "[64/150][5/8] Loss_D: 0.2961 Loss_G: 2.8706\n",
      "[64/150][6/8] Loss_D: 0.2436 Loss_G: 3.0090\n",
      "[64/150][7/8] Loss_D: 0.2375 Loss_G: 2.9443\n",
      "[65/150][0/8] Loss_D: 0.3036 Loss_G: 3.2589\n",
      "[65/150][1/8] Loss_D: 0.2891 Loss_G: 3.3681\n",
      "[65/150][2/8] Loss_D: 0.4518 Loss_G: 4.0935\n",
      "[65/150][3/8] Loss_D: 0.6320 Loss_G: 2.1418\n",
      "[65/150][4/8] Loss_D: 0.6217 Loss_G: 6.0225\n",
      "[65/150][5/8] Loss_D: 1.0577 Loss_G: 0.0826\n",
      "[65/150][6/8] Loss_D: 2.6288 Loss_G: 7.7563\n",
      "[65/150][7/8] Loss_D: 4.2942 Loss_G: 0.5732\n",
      "[66/150][0/8] Loss_D: 1.7856 Loss_G: 3.0906\n",
      "[66/150][1/8] Loss_D: 1.6791 Loss_G: 1.2162\n",
      "[66/150][2/8] Loss_D: 1.0255 Loss_G: 1.5399\n",
      "[66/150][3/8] Loss_D: 1.1644 Loss_G: 2.8319\n",
      "[66/150][4/8] Loss_D: 1.8453 Loss_G: 0.4227\n",
      "[66/150][5/8] Loss_D: 1.6277 Loss_G: 2.6326\n",
      "[66/150][6/8] Loss_D: 1.5100 Loss_G: 0.6742\n",
      "[66/150][7/8] Loss_D: 1.3859 Loss_G: 3.3316\n",
      "[67/150][0/8] Loss_D: 1.8296 Loss_G: 0.2877\n",
      "[67/150][1/8] Loss_D: 1.8447 Loss_G: 2.4043\n",
      "[67/150][2/8] Loss_D: 1.1629 Loss_G: 1.2033\n",
      "[67/150][3/8] Loss_D: 1.0137 Loss_G: 1.1094\n",
      "[67/150][4/8] Loss_D: 1.0879 Loss_G: 1.8756\n",
      "[67/150][5/8] Loss_D: 1.2211 Loss_G: 0.7068\n",
      "[67/150][6/8] Loss_D: 1.4830 Loss_G: 2.2900\n",
      "[67/150][7/8] Loss_D: 1.6137 Loss_G: 0.4992\n",
      "[68/150][0/8] Loss_D: 1.7406 Loss_G: 2.8446\n",
      "[68/150][1/8] Loss_D: 1.9303 Loss_G: 0.7697\n",
      "[68/150][2/8] Loss_D: 1.0631 Loss_G: 1.6692\n",
      "[68/150][3/8] Loss_D: 1.0382 Loss_G: 1.5656\n",
      "[68/150][4/8] Loss_D: 1.1698 Loss_G: 0.8376\n",
      "[68/150][5/8] Loss_D: 1.3836 Loss_G: 2.1256\n",
      "[68/150][6/8] Loss_D: 1.5014 Loss_G: 0.5980\n",
      "[68/150][7/8] Loss_D: 1.0492 Loss_G: 2.8431\n",
      "[69/150][0/8] Loss_D: 1.0127 Loss_G: 0.6099\n",
      "[69/150][1/8] Loss_D: 1.7395 Loss_G: 3.6400\n",
      "[69/150][2/8] Loss_D: 1.2826 Loss_G: 1.6740\n",
      "[69/150][3/8] Loss_D: 1.0773 Loss_G: 3.5019\n",
      "[69/150][4/8] Loss_D: 1.7236 Loss_G: 0.2971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69/150][5/8] Loss_D: 2.0962 Loss_G: 2.6574\n",
      "[69/150][6/8] Loss_D: 1.4297 Loss_G: 0.9469\n",
      "[69/150][7/8] Loss_D: 1.0878 Loss_G: 1.9228\n",
      "[70/150][0/8] Loss_D: 1.0779 Loss_G: 1.1226\n",
      "[70/150][1/8] Loss_D: 1.1611 Loss_G: 1.7591\n",
      "[70/150][2/8] Loss_D: 1.0240 Loss_G: 0.9757\n",
      "[70/150][3/8] Loss_D: 1.2950 Loss_G: 3.2326\n",
      "[70/150][4/8] Loss_D: 1.4905 Loss_G: 1.5996\n",
      "[70/150][5/8] Loss_D: 1.2311 Loss_G: 3.7535\n",
      "[70/150][6/8] Loss_D: 1.5904 Loss_G: 0.9295\n",
      "[70/150][7/8] Loss_D: 1.2203 Loss_G: 3.3454\n",
      "[71/150][0/8] Loss_D: 1.6156 Loss_G: 0.4062\n",
      "[71/150][1/8] Loss_D: 1.2766 Loss_G: 3.0477\n",
      "[71/150][2/8] Loss_D: 1.0482 Loss_G: 0.9690\n",
      "[71/150][3/8] Loss_D: 1.3772 Loss_G: 3.6661\n",
      "[71/150][4/8] Loss_D: 1.7940 Loss_G: 0.3989\n",
      "[71/150][5/8] Loss_D: 1.4680 Loss_G: 3.5260\n",
      "[71/150][6/8] Loss_D: 1.4412 Loss_G: 0.6246\n",
      "[71/150][7/8] Loss_D: 1.2634 Loss_G: 3.1363\n",
      "[72/150][0/8] Loss_D: 1.2858 Loss_G: 0.7029\n",
      "[72/150][1/8] Loss_D: 1.0485 Loss_G: 2.8781\n",
      "[72/150][2/8] Loss_D: 0.9276 Loss_G: 1.8431\n",
      "[72/150][3/8] Loss_D: 1.8320 Loss_G: 2.8191\n",
      "[72/150][4/8] Loss_D: 1.7695 Loss_G: 1.2074\n",
      "[72/150][5/8] Loss_D: 1.3350 Loss_G: 2.5340\n",
      "[72/150][6/8] Loss_D: 1.3703 Loss_G: 0.7711\n",
      "[72/150][7/8] Loss_D: 1.3230 Loss_G: 2.7104\n",
      "[73/150][0/8] Loss_D: 1.6520 Loss_G: 0.7598\n",
      "[73/150][1/8] Loss_D: 1.0933 Loss_G: 2.3689\n",
      "[73/150][2/8] Loss_D: 1.0114 Loss_G: 1.5083\n",
      "[73/150][3/8] Loss_D: 0.5449 Loss_G: 1.9462\n",
      "[73/150][4/8] Loss_D: 0.7294 Loss_G: 3.7860\n",
      "[73/150][5/8] Loss_D: 0.4906 Loss_G: 3.9219\n",
      "[73/150][6/8] Loss_D: 0.7439 Loss_G: 5.1675\n",
      "[73/150][7/8] Loss_D: 0.3866 Loss_G: 3.1645\n",
      "[74/150][0/8] Loss_D: 0.2187 Loss_G: 3.2755\n",
      "[74/150][1/8] Loss_D: 0.1450 Loss_G: 3.5734\n",
      "[74/150][2/8] Loss_D: 0.2399 Loss_G: 3.6294\n",
      "[74/150][3/8] Loss_D: 0.4915 Loss_G: 4.3921\n",
      "[74/150][4/8] Loss_D: 0.4371 Loss_G: 2.5463\n",
      "[74/150][5/8] Loss_D: 0.7175 Loss_G: 6.8332\n",
      "[74/150][6/8] Loss_D: 1.6964 Loss_G: 2.6399\n",
      "[74/150][7/8] Loss_D: 0.6746 Loss_G: 3.4723\n",
      "[75/150][0/8] Loss_D: 1.5364 Loss_G: 0.2136\n",
      "[75/150][1/8] Loss_D: 1.8760 Loss_G: 5.8803\n",
      "[75/150][2/8] Loss_D: 2.1878 Loss_G: 0.3598\n",
      "[75/150][3/8] Loss_D: 2.3229 Loss_G: 4.0771\n",
      "[75/150][4/8] Loss_D: 2.6368 Loss_G: 1.3355\n",
      "[75/150][5/8] Loss_D: 1.2311 Loss_G: 3.0030\n",
      "[75/150][6/8] Loss_D: 1.7133 Loss_G: 0.2126\n",
      "[75/150][7/8] Loss_D: 2.0272 Loss_G: 2.5422\n",
      "[76/150][0/8] Loss_D: 1.7851 Loss_G: 0.6774\n",
      "[76/150][1/8] Loss_D: 1.4024 Loss_G: 1.6707\n",
      "[76/150][2/8] Loss_D: 1.1874 Loss_G: 1.1728\n",
      "[76/150][3/8] Loss_D: 0.9716 Loss_G: 1.3907\n",
      "[76/150][4/8] Loss_D: 1.0836 Loss_G: 1.9067\n",
      "[76/150][5/8] Loss_D: 1.2723 Loss_G: 0.5076\n",
      "[76/150][6/8] Loss_D: 1.6920 Loss_G: 2.4379\n",
      "[76/150][7/8] Loss_D: 1.9449 Loss_G: 0.3624\n",
      "[77/150][0/8] Loss_D: 1.5717 Loss_G: 2.2461\n",
      "[77/150][1/8] Loss_D: 1.3427 Loss_G: 0.7526\n",
      "[77/150][2/8] Loss_D: 1.3865 Loss_G: 1.8932\n",
      "[77/150][3/8] Loss_D: 1.5948 Loss_G: 0.5445\n",
      "[77/150][4/8] Loss_D: 1.2200 Loss_G: 2.2557\n",
      "[77/150][5/8] Loss_D: 1.1453 Loss_G: 0.7824\n",
      "[77/150][6/8] Loss_D: 1.2016 Loss_G: 2.1449\n",
      "[77/150][7/8] Loss_D: 1.3737 Loss_G: 0.8658\n",
      "[78/150][0/8] Loss_D: 1.1767 Loss_G: 1.7320\n",
      "[78/150][1/8] Loss_D: 1.2458 Loss_G: 0.4941\n",
      "[78/150][2/8] Loss_D: 1.5676 Loss_G: 3.4442\n",
      "[78/150][3/8] Loss_D: 2.8346 Loss_G: 0.1617\n",
      "[78/150][4/8] Loss_D: 2.0732 Loss_G: 1.9546\n",
      "[78/150][5/8] Loss_D: 1.8721 Loss_G: 0.7235\n",
      "[78/150][6/8] Loss_D: 1.2569 Loss_G: 1.0102\n",
      "[78/150][7/8] Loss_D: 1.0616 Loss_G: 1.5791\n",
      "[79/150][0/8] Loss_D: 1.3002 Loss_G: 0.9904\n",
      "[79/150][1/8] Loss_D: 1.4134 Loss_G: 0.7041\n",
      "[79/150][2/8] Loss_D: 1.3340 Loss_G: 1.1935\n",
      "[79/150][3/8] Loss_D: 1.2112 Loss_G: 1.1860\n",
      "[79/150][4/8] Loss_D: 1.3349 Loss_G: 1.0047\n",
      "[79/150][5/8] Loss_D: 1.3302 Loss_G: 0.9005\n",
      "[79/150][6/8] Loss_D: 1.3751 Loss_G: 1.8652\n",
      "[79/150][7/8] Loss_D: 1.4443 Loss_G: 0.4877\n",
      "[80/150][0/8] Loss_D: 1.2725 Loss_G: 1.7304\n",
      "[80/150][1/8] Loss_D: 1.2182 Loss_G: 0.7622\n",
      "[80/150][2/8] Loss_D: 1.3231 Loss_G: 1.5661\n",
      "[80/150][3/8] Loss_D: 1.3684 Loss_G: 0.5477\n",
      "[80/150][4/8] Loss_D: 1.2760 Loss_G: 1.9292\n",
      "[80/150][5/8] Loss_D: 1.3209 Loss_G: 0.5114\n",
      "[80/150][6/8] Loss_D: 1.3902 Loss_G: 2.2655\n",
      "[80/150][7/8] Loss_D: 1.4881 Loss_G: 0.4911\n",
      "[81/150][0/8] Loss_D: 1.2537 Loss_G: 2.6310\n",
      "[81/150][1/8] Loss_D: 1.3882 Loss_G: 0.3855\n",
      "[81/150][2/8] Loss_D: 1.7030 Loss_G: 2.3113\n",
      "[81/150][3/8] Loss_D: 1.8524 Loss_G: 0.5586\n",
      "[81/150][4/8] Loss_D: 1.3098 Loss_G: 1.8910\n",
      "[81/150][5/8] Loss_D: 1.1749 Loss_G: 1.3366\n",
      "[81/150][6/8] Loss_D: 1.4060 Loss_G: 0.7555\n",
      "[81/150][7/8] Loss_D: 1.0937 Loss_G: 1.5864\n",
      "[82/150][0/8] Loss_D: 1.0940 Loss_G: 0.8929\n",
      "[82/150][1/8] Loss_D: 1.1808 Loss_G: 1.3544\n",
      "[82/150][2/8] Loss_D: 1.3803 Loss_G: 1.0725\n",
      "[82/150][3/8] Loss_D: 1.1755 Loss_G: 1.4989\n",
      "[82/150][4/8] Loss_D: 1.2657 Loss_G: 0.5115\n",
      "[82/150][5/8] Loss_D: 1.5074 Loss_G: 2.6258\n",
      "[82/150][6/8] Loss_D: 2.3145 Loss_G: 0.2612\n",
      "[82/150][7/8] Loss_D: 1.9363 Loss_G: 2.6429\n",
      "[83/150][0/8] Loss_D: 1.8219 Loss_G: 0.6947\n",
      "[83/150][1/8] Loss_D: 1.1719 Loss_G: 1.3676\n",
      "[83/150][2/8] Loss_D: 1.0794 Loss_G: 1.5498\n",
      "[83/150][3/8] Loss_D: 1.4483 Loss_G: 0.6418\n",
      "[83/150][4/8] Loss_D: 1.3655 Loss_G: 1.6215\n",
      "[83/150][5/8] Loss_D: 1.4190 Loss_G: 0.8607\n",
      "[83/150][6/8] Loss_D: 1.2994 Loss_G: 1.2214\n",
      "[83/150][7/8] Loss_D: 1.1387 Loss_G: 1.2365\n",
      "[84/150][0/8] Loss_D: 1.4799 Loss_G: 1.7056\n",
      "[84/150][1/8] Loss_D: 1.7558 Loss_G: 0.7540\n",
      "[84/150][2/8] Loss_D: 0.8941 Loss_G: 2.4464\n",
      "[84/150][3/8] Loss_D: 1.0301 Loss_G: 0.7759\n",
      "[84/150][4/8] Loss_D: 1.8526 Loss_G: 3.8007\n",
      "[84/150][5/8] Loss_D: 3.5318 Loss_G: 0.3843\n",
      "[84/150][6/8] Loss_D: 1.3063 Loss_G: 1.3187\n",
      "[84/150][7/8] Loss_D: 0.6853 Loss_G: 2.1922\n",
      "[85/150][0/8] Loss_D: 0.6370 Loss_G: 1.7026\n",
      "[85/150][1/8] Loss_D: 0.8104 Loss_G: 2.8068\n",
      "[85/150][2/8] Loss_D: 1.8740 Loss_G: 0.1713\n",
      "[85/150][3/8] Loss_D: 2.1532 Loss_G: 2.4343\n",
      "[85/150][4/8] Loss_D: 1.4011 Loss_G: 1.2456\n",
      "[85/150][5/8] Loss_D: 1.0102 Loss_G: 0.6433\n",
      "[85/150][6/8] Loss_D: 1.1973 Loss_G: 1.9397\n",
      "[85/150][7/8] Loss_D: 1.2527 Loss_G: 0.7252\n",
      "[86/150][0/8] Loss_D: 1.3419 Loss_G: 1.7316\n",
      "[86/150][1/8] Loss_D: 1.7690 Loss_G: 0.6202\n",
      "[86/150][2/8] Loss_D: 1.1100 Loss_G: 1.7071\n",
      "[86/150][3/8] Loss_D: 1.0180 Loss_G: 1.3965\n",
      "[86/150][4/8] Loss_D: 1.5011 Loss_G: 1.5685\n",
      "[86/150][5/8] Loss_D: 2.0355 Loss_G: 0.9354\n",
      "[86/150][6/8] Loss_D: 0.9017 Loss_G: 2.3664\n",
      "[86/150][7/8] Loss_D: 1.0971 Loss_G: 0.5130\n",
      "[87/150][0/8] Loss_D: 1.3268 Loss_G: 3.8160\n",
      "[87/150][1/8] Loss_D: 1.7680 Loss_G: 0.2731\n",
      "[87/150][2/8] Loss_D: 1.8251 Loss_G: 2.1922\n",
      "[87/150][3/8] Loss_D: 1.4253 Loss_G: 1.0168\n",
      "[87/150][4/8] Loss_D: 1.1603 Loss_G: 0.9701\n",
      "[87/150][5/8] Loss_D: 1.2771 Loss_G: 1.2390\n",
      "[87/150][6/8] Loss_D: 1.3479 Loss_G: 0.6801\n",
      "[87/150][7/8] Loss_D: 1.2720 Loss_G: 1.3559\n",
      "[88/150][0/8] Loss_D: 1.2422 Loss_G: 1.3165\n",
      "[88/150][1/8] Loss_D: 1.4418 Loss_G: 0.6369\n",
      "[88/150][2/8] Loss_D: 1.3715 Loss_G: 1.4940\n",
      "[88/150][3/8] Loss_D: 1.2102 Loss_G: 1.0612\n",
      "[88/150][4/8] Loss_D: 1.5084 Loss_G: 0.9276\n",
      "[88/150][5/8] Loss_D: 1.2395 Loss_G: 1.1815\n",
      "[88/150][6/8] Loss_D: 1.1789 Loss_G: 1.5383\n",
      "[88/150][7/8] Loss_D: 1.4523 Loss_G: 0.5861\n",
      "[89/150][0/8] Loss_D: 1.2925 Loss_G: 1.5401\n",
      "[89/150][1/8] Loss_D: 1.2362 Loss_G: 1.2527\n",
      "[89/150][2/8] Loss_D: 1.2760 Loss_G: 1.1728\n",
      "[89/150][3/8] Loss_D: 1.1164 Loss_G: 1.3335\n",
      "[89/150][4/8] Loss_D: 1.2686 Loss_G: 1.0222\n",
      "[89/150][5/8] Loss_D: 1.3949 Loss_G: 1.1633\n",
      "[89/150][6/8] Loss_D: 1.3920 Loss_G: 1.3890\n",
      "[89/150][7/8] Loss_D: 1.4233 Loss_G: 0.7878\n",
      "[90/150][0/8] Loss_D: 1.0770 Loss_G: 2.6448\n",
      "[90/150][1/8] Loss_D: 1.4981 Loss_G: 0.2015\n",
      "[90/150][2/8] Loss_D: 2.2672 Loss_G: 1.8999\n",
      "[90/150][3/8] Loss_D: 1.8485 Loss_G: 0.8519\n",
      "[90/150][4/8] Loss_D: 1.1465 Loss_G: 1.3713\n",
      "[90/150][5/8] Loss_D: 1.3335 Loss_G: 1.0920\n",
      "[90/150][6/8] Loss_D: 1.4829 Loss_G: 0.6918\n",
      "[90/150][7/8] Loss_D: 1.1240 Loss_G: 1.9812\n",
      "[91/150][0/8] Loss_D: 1.1976 Loss_G: 0.7132\n",
      "[91/150][1/8] Loss_D: 1.7549 Loss_G: 1.7723\n",
      "[91/150][2/8] Loss_D: 1.9061 Loss_G: 0.9253\n",
      "[91/150][3/8] Loss_D: 0.9349 Loss_G: 2.3193\n",
      "[91/150][4/8] Loss_D: 1.0563 Loss_G: 0.6859\n",
      "[91/150][5/8] Loss_D: 2.1189 Loss_G: 1.7943\n",
      "[91/150][6/8] Loss_D: 1.9423 Loss_G: 1.1153\n",
      "[91/150][7/8] Loss_D: 0.9149 Loss_G: 1.6410\n",
      "[92/150][0/8] Loss_D: 0.9000 Loss_G: 1.3996\n",
      "[92/150][1/8] Loss_D: 1.1611 Loss_G: 1.3632\n",
      "[92/150][2/8] Loss_D: 1.7553 Loss_G: 1.6118\n",
      "[92/150][3/8] Loss_D: 1.6003 Loss_G: 0.6409\n",
      "[92/150][4/8] Loss_D: 1.1985 Loss_G: 2.5213\n",
      "[92/150][5/8] Loss_D: 1.2259 Loss_G: 1.0031\n",
      "[92/150][6/8] Loss_D: 1.4725 Loss_G: 1.3356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92/150][7/8] Loss_D: 1.3723 Loss_G: 0.8013\n",
      "[93/150][0/8] Loss_D: 1.1127 Loss_G: 2.4530\n",
      "[93/150][1/8] Loss_D: 1.1971 Loss_G: 0.6100\n",
      "[93/150][2/8] Loss_D: 1.4926 Loss_G: 1.9550\n",
      "[93/150][3/8] Loss_D: 1.3395 Loss_G: 0.9810\n",
      "[93/150][4/8] Loss_D: 1.1126 Loss_G: 1.7918\n",
      "[93/150][5/8] Loss_D: 1.2370 Loss_G: 0.9909\n",
      "[93/150][6/8] Loss_D: 1.7790 Loss_G: 1.3220\n",
      "[93/150][7/8] Loss_D: 1.4900 Loss_G: 1.0272\n",
      "[94/150][0/8] Loss_D: 1.0742 Loss_G: 2.6568\n",
      "[94/150][1/8] Loss_D: 1.5295 Loss_G: 0.3786\n",
      "[94/150][2/8] Loss_D: 1.3513 Loss_G: 3.8598\n",
      "[94/150][3/8] Loss_D: 1.8701 Loss_G: 0.2879\n",
      "[94/150][4/8] Loss_D: 2.4750 Loss_G: 2.3793\n",
      "[94/150][5/8] Loss_D: 1.8739 Loss_G: 0.9727\n",
      "[94/150][6/8] Loss_D: 1.2724 Loss_G: 0.8849\n",
      "[94/150][7/8] Loss_D: 1.1711 Loss_G: 1.7039\n",
      "[95/150][0/8] Loss_D: 1.2945 Loss_G: 0.8344\n",
      "[95/150][1/8] Loss_D: 1.6396 Loss_G: 1.4170\n",
      "[95/150][2/8] Loss_D: 2.0049 Loss_G: 0.6446\n",
      "[95/150][3/8] Loss_D: 1.3823 Loss_G: 1.2791\n",
      "[95/150][4/8] Loss_D: 1.2592 Loss_G: 1.0290\n",
      "[95/150][5/8] Loss_D: 1.1950 Loss_G: 0.9833\n",
      "[95/150][6/8] Loss_D: 1.1848 Loss_G: 1.1114\n",
      "[95/150][7/8] Loss_D: 1.1708 Loss_G: 0.9803\n",
      "[96/150][0/8] Loss_D: 1.2132 Loss_G: 1.2973\n",
      "[96/150][1/8] Loss_D: 1.1964 Loss_G: 0.8533\n",
      "[96/150][2/8] Loss_D: 1.3056 Loss_G: 1.5793\n",
      "[96/150][3/8] Loss_D: 1.6231 Loss_G: 0.4561\n",
      "[96/150][4/8] Loss_D: 1.2795 Loss_G: 1.9785\n",
      "[96/150][5/8] Loss_D: 1.3736 Loss_G: 1.0931\n",
      "[96/150][6/8] Loss_D: 1.1741 Loss_G: 1.3360\n",
      "[96/150][7/8] Loss_D: 1.2175 Loss_G: 2.2040\n",
      "[97/150][0/8] Loss_D: 1.8750 Loss_G: 0.2790\n",
      "[97/150][1/8] Loss_D: 1.6669 Loss_G: 2.6070\n",
      "[97/150][2/8] Loss_D: 1.5863 Loss_G: 0.7196\n",
      "[97/150][3/8] Loss_D: 1.2002 Loss_G: 1.4497\n",
      "[97/150][4/8] Loss_D: 1.0822 Loss_G: 1.2540\n",
      "[97/150][5/8] Loss_D: 1.1479 Loss_G: 0.9159\n",
      "[97/150][6/8] Loss_D: 1.3170 Loss_G: 1.7573\n",
      "[97/150][7/8] Loss_D: 1.6269 Loss_G: 0.2952\n",
      "[98/150][0/8] Loss_D: 1.5952 Loss_G: 3.9744\n",
      "[98/150][1/8] Loss_D: 2.1884 Loss_G: 0.4780\n",
      "[98/150][2/8] Loss_D: 1.2884 Loss_G: 2.5641\n",
      "[98/150][3/8] Loss_D: 1.2709 Loss_G: 1.1580\n",
      "[98/150][4/8] Loss_D: 1.2034 Loss_G: 1.5489\n",
      "[98/150][5/8] Loss_D: 1.4753 Loss_G: 0.8708\n",
      "[98/150][6/8] Loss_D: 1.4586 Loss_G: 1.6676\n",
      "[98/150][7/8] Loss_D: 1.3266 Loss_G: 0.5924\n",
      "[99/150][0/8] Loss_D: 1.2235 Loss_G: 1.8361\n",
      "[99/150][1/8] Loss_D: 1.3608 Loss_G: 0.9015\n",
      "[99/150][2/8] Loss_D: 1.1794 Loss_G: 1.7181\n",
      "[99/150][3/8] Loss_D: 1.3869 Loss_G: 0.5476\n",
      "[99/150][4/8] Loss_D: 1.4408 Loss_G: 1.9726\n",
      "[99/150][5/8] Loss_D: 1.6565 Loss_G: 0.4326\n",
      "[99/150][6/8] Loss_D: 1.4448 Loss_G: 2.0886\n",
      "[99/150][7/8] Loss_D: 1.3412 Loss_G: 0.7777\n",
      "[100/150][0/8] Loss_D: 1.2855 Loss_G: 2.2575\n",
      "[100/150][1/8] Loss_D: 1.2992 Loss_G: 0.4859\n",
      "[100/150][2/8] Loss_D: 1.4671 Loss_G: 2.9313\n",
      "[100/150][3/8] Loss_D: 1.7084 Loss_G: 0.6336\n",
      "[100/150][4/8] Loss_D: 1.3872 Loss_G: 2.1306\n",
      "[100/150][5/8] Loss_D: 1.2789 Loss_G: 1.0345\n",
      "[100/150][6/8] Loss_D: 1.1712 Loss_G: 0.7606\n",
      "[100/150][7/8] Loss_D: 1.3021 Loss_G: 2.4079\n",
      "[101/150][0/8] Loss_D: 1.5624 Loss_G: 0.4999\n",
      "[101/150][1/8] Loss_D: 1.5629 Loss_G: 2.9713\n",
      "[101/150][2/8] Loss_D: 2.3937 Loss_G: 0.6953\n",
      "[101/150][3/8] Loss_D: 1.1939 Loss_G: 2.6096\n",
      "[101/150][4/8] Loss_D: 1.8510 Loss_G: 0.4144\n",
      "[101/150][5/8] Loss_D: 1.8477 Loss_G: 1.4982\n",
      "[101/150][6/8] Loss_D: 1.4909 Loss_G: 0.9948\n",
      "[101/150][7/8] Loss_D: 1.1441 Loss_G: 1.1930\n",
      "[102/150][0/8] Loss_D: 1.3093 Loss_G: 1.3117\n",
      "[102/150][1/8] Loss_D: 1.7436 Loss_G: 0.5061\n",
      "[102/150][2/8] Loss_D: 1.4546 Loss_G: 1.3129\n",
      "[102/150][3/8] Loss_D: 1.2708 Loss_G: 0.9861\n",
      "[102/150][4/8] Loss_D: 1.1514 Loss_G: 1.1662\n",
      "[102/150][5/8] Loss_D: 1.0563 Loss_G: 1.1725\n",
      "[102/150][6/8] Loss_D: 1.2046 Loss_G: 1.4539\n",
      "[102/150][7/8] Loss_D: 1.0759 Loss_G: 1.2425\n",
      "[103/150][0/8] Loss_D: 1.1949 Loss_G: 2.2179\n",
      "[103/150][1/8] Loss_D: 1.7128 Loss_G: 0.6904\n",
      "[103/150][2/8] Loss_D: 1.1299 Loss_G: 3.3526\n",
      "[103/150][3/8] Loss_D: 1.8867 Loss_G: 0.1879\n",
      "[103/150][4/8] Loss_D: 2.1708 Loss_G: 2.0257\n",
      "[103/150][5/8] Loss_D: 1.5563 Loss_G: 1.0080\n",
      "[103/150][6/8] Loss_D: 1.3318 Loss_G: 1.3884\n",
      "[103/150][7/8] Loss_D: 1.4333 Loss_G: 0.6793\n",
      "[104/150][0/8] Loss_D: 1.3142 Loss_G: 1.3421\n",
      "[104/150][1/8] Loss_D: 1.3164 Loss_G: 0.9424\n",
      "[104/150][2/8] Loss_D: 1.1960 Loss_G: 1.1770\n",
      "[104/150][3/8] Loss_D: 1.2926 Loss_G: 1.1120\n",
      "[104/150][4/8] Loss_D: 1.3556 Loss_G: 0.8209\n",
      "[104/150][5/8] Loss_D: 1.4492 Loss_G: 1.1409\n",
      "[104/150][6/8] Loss_D: 1.3616 Loss_G: 0.8873\n",
      "[104/150][7/8] Loss_D: 1.2639 Loss_G: 1.6954\n",
      "[105/150][0/8] Loss_D: 1.3833 Loss_G: 0.6371\n",
      "[105/150][1/8] Loss_D: 1.4144 Loss_G: 2.6193\n",
      "[105/150][2/8] Loss_D: 1.8085 Loss_G: 0.6172\n",
      "[105/150][3/8] Loss_D: 1.7461 Loss_G: 2.2665\n",
      "[105/150][4/8] Loss_D: 1.4572 Loss_G: 0.8060\n",
      "[105/150][5/8] Loss_D: 1.2964 Loss_G: 2.0152\n",
      "[105/150][6/8] Loss_D: 1.5469 Loss_G: 0.9483\n",
      "[105/150][7/8] Loss_D: 1.3665 Loss_G: 1.7862\n",
      "[106/150][0/8] Loss_D: 1.4116 Loss_G: 1.1969\n",
      "[106/150][1/8] Loss_D: 1.0655 Loss_G: 1.2968\n",
      "[106/150][2/8] Loss_D: 1.1280 Loss_G: 1.5182\n",
      "[106/150][3/8] Loss_D: 1.3940 Loss_G: 2.0629\n",
      "[106/150][4/8] Loss_D: 1.3327 Loss_G: 0.6722\n",
      "[106/150][5/8] Loss_D: 1.6487 Loss_G: 2.8924\n",
      "[106/150][6/8] Loss_D: 2.2025 Loss_G: 0.4218\n",
      "[106/150][7/8] Loss_D: 1.3924 Loss_G: 2.0633\n",
      "[107/150][0/8] Loss_D: 1.0068 Loss_G: 1.2016\n",
      "[107/150][1/8] Loss_D: 1.0496 Loss_G: 1.8959\n",
      "[107/150][2/8] Loss_D: 1.5166 Loss_G: 1.8223\n",
      "[107/150][3/8] Loss_D: 1.3025 Loss_G: 1.2127\n",
      "[107/150][4/8] Loss_D: 1.4919 Loss_G: 1.4968\n",
      "[107/150][5/8] Loss_D: 1.6579 Loss_G: 1.0933\n",
      "[107/150][6/8] Loss_D: 1.1692 Loss_G: 2.4868\n",
      "[107/150][7/8] Loss_D: 1.5462 Loss_G: 0.6630\n",
      "[108/150][0/8] Loss_D: 1.4145 Loss_G: 1.7264\n",
      "[108/150][1/8] Loss_D: 1.3326 Loss_G: 0.8201\n",
      "[108/150][2/8] Loss_D: 1.2810 Loss_G: 1.5713\n",
      "[108/150][3/8] Loss_D: 1.5156 Loss_G: 0.8185\n",
      "[108/150][4/8] Loss_D: 1.2775 Loss_G: 1.6484\n",
      "[108/150][5/8] Loss_D: 1.1861 Loss_G: 0.8820\n",
      "[108/150][6/8] Loss_D: 1.4838 Loss_G: 1.4459\n",
      "[108/150][7/8] Loss_D: 1.4585 Loss_G: 0.8330\n",
      "[109/150][0/8] Loss_D: 1.2250 Loss_G: 1.5326\n",
      "[109/150][1/8] Loss_D: 1.4097 Loss_G: 0.7426\n",
      "[109/150][2/8] Loss_D: 1.2880 Loss_G: 2.6843\n",
      "[109/150][3/8] Loss_D: 1.5855 Loss_G: 0.1694\n",
      "[109/150][4/8] Loss_D: 2.3618 Loss_G: 2.4518\n",
      "[109/150][5/8] Loss_D: 2.2356 Loss_G: 0.6166\n",
      "[109/150][6/8] Loss_D: 1.5439 Loss_G: 0.8083\n",
      "[109/150][7/8] Loss_D: 1.3826 Loss_G: 1.1769\n",
      "[110/150][0/8] Loss_D: 1.5584 Loss_G: 0.5844\n",
      "[110/150][1/8] Loss_D: 1.3753 Loss_G: 1.0507\n",
      "[110/150][2/8] Loss_D: 1.2698 Loss_G: 0.8398\n",
      "[110/150][3/8] Loss_D: 1.3390 Loss_G: 0.7503\n",
      "[110/150][4/8] Loss_D: 1.3329 Loss_G: 1.0389\n",
      "[110/150][5/8] Loss_D: 1.2972 Loss_G: 0.8464\n",
      "[110/150][6/8] Loss_D: 1.3199 Loss_G: 1.0029\n",
      "[110/150][7/8] Loss_D: 1.3747 Loss_G: 0.8721\n",
      "[111/150][0/8] Loss_D: 1.2000 Loss_G: 1.4150\n",
      "[111/150][1/8] Loss_D: 1.2040 Loss_G: 0.7513\n",
      "[111/150][2/8] Loss_D: 1.2524 Loss_G: 1.3574\n",
      "[111/150][3/8] Loss_D: 1.3125 Loss_G: 1.0785\n",
      "[111/150][4/8] Loss_D: 1.2577 Loss_G: 1.1100\n",
      "[111/150][5/8] Loss_D: 1.3617 Loss_G: 1.1042\n",
      "[111/150][6/8] Loss_D: 1.2200 Loss_G: 1.2799\n",
      "[111/150][7/8] Loss_D: 1.5393 Loss_G: 1.0047\n",
      "[112/150][0/8] Loss_D: 1.1079 Loss_G: 1.3871\n",
      "[112/150][1/8] Loss_D: 1.4292 Loss_G: 1.1636\n",
      "[112/150][2/8] Loss_D: 1.2913 Loss_G: 0.8181\n",
      "[112/150][3/8] Loss_D: 1.0030 Loss_G: 2.3699\n",
      "[112/150][4/8] Loss_D: 1.2992 Loss_G: 0.1655\n",
      "[112/150][5/8] Loss_D: 2.4426 Loss_G: 2.7871\n",
      "[112/150][6/8] Loss_D: 2.4092 Loss_G: 0.6992\n",
      "[112/150][7/8] Loss_D: 1.2047 Loss_G: 1.0722\n",
      "[113/150][0/8] Loss_D: 1.2507 Loss_G: 1.5217\n",
      "[113/150][1/8] Loss_D: 1.4762 Loss_G: 0.7609\n",
      "[113/150][2/8] Loss_D: 1.3385 Loss_G: 1.2225\n",
      "[113/150][3/8] Loss_D: 1.2978 Loss_G: 1.3815\n",
      "[113/150][4/8] Loss_D: 1.4467 Loss_G: 0.5285\n",
      "[113/150][5/8] Loss_D: 1.4550 Loss_G: 1.5147\n",
      "[113/150][6/8] Loss_D: 1.4643 Loss_G: 0.7944\n",
      "[113/150][7/8] Loss_D: 1.2658 Loss_G: 1.2320\n",
      "[114/150][0/8] Loss_D: 1.2098 Loss_G: 0.9896\n",
      "[114/150][1/8] Loss_D: 1.2017 Loss_G: 0.9130\n",
      "[114/150][2/8] Loss_D: 1.3707 Loss_G: 1.0497\n",
      "[114/150][3/8] Loss_D: 1.3465 Loss_G: 0.8587\n",
      "[114/150][4/8] Loss_D: 1.2357 Loss_G: 1.4149\n",
      "[114/150][5/8] Loss_D: 1.5232 Loss_G: 0.6063\n",
      "[114/150][6/8] Loss_D: 1.5140 Loss_G: 1.4451\n",
      "[114/150][7/8] Loss_D: 1.3107 Loss_G: 0.7587\n",
      "[115/150][0/8] Loss_D: 1.3148 Loss_G: 1.5711\n",
      "[115/150][1/8] Loss_D: 1.2566 Loss_G: 0.9822\n",
      "[115/150][2/8] Loss_D: 1.2175 Loss_G: 1.4822\n",
      "[115/150][3/8] Loss_D: 1.1870 Loss_G: 1.0888\n",
      "[115/150][4/8] Loss_D: 1.3925 Loss_G: 1.7259\n",
      "[115/150][5/8] Loss_D: 1.2990 Loss_G: 1.3030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[115/150][6/8] Loss_D: 1.4379 Loss_G: 3.2591\n",
      "[115/150][7/8] Loss_D: 2.3609 Loss_G: 0.5233\n",
      "[116/150][0/8] Loss_D: 0.6862 Loss_G: 2.5492\n",
      "[116/150][1/8] Loss_D: 0.8289 Loss_G: 4.5436\n",
      "[116/150][2/8] Loss_D: 1.5969 Loss_G: 0.2664\n",
      "[116/150][3/8] Loss_D: 2.5746 Loss_G: 3.3604\n",
      "[116/150][4/8] Loss_D: 1.3988 Loss_G: 1.2243\n",
      "[116/150][5/8] Loss_D: 1.0294 Loss_G: 1.0261\n",
      "[116/150][6/8] Loss_D: 1.0182 Loss_G: 2.4575\n",
      "[116/150][7/8] Loss_D: 1.4133 Loss_G: 0.4378\n",
      "[117/150][0/8] Loss_D: 0.9878 Loss_G: 3.2145\n",
      "[117/150][1/8] Loss_D: 1.3146 Loss_G: 0.4221\n",
      "[117/150][2/8] Loss_D: 1.2817 Loss_G: 3.9365\n",
      "[117/150][3/8] Loss_D: 1.8339 Loss_G: 0.6484\n",
      "[117/150][4/8] Loss_D: 1.0574 Loss_G: 3.0928\n",
      "[117/150][5/8] Loss_D: 0.9903 Loss_G: 1.2653\n",
      "[117/150][6/8] Loss_D: 0.8323 Loss_G: 2.5563\n",
      "[117/150][7/8] Loss_D: 1.0364 Loss_G: 2.0690\n",
      "[118/150][0/8] Loss_D: 0.9995 Loss_G: 1.9116\n",
      "[118/150][1/8] Loss_D: 1.2444 Loss_G: 2.9864\n",
      "[118/150][2/8] Loss_D: 0.6364 Loss_G: 1.6923\n",
      "[118/150][3/8] Loss_D: 0.7627 Loss_G: 3.2277\n",
      "[118/150][4/8] Loss_D: 1.0825 Loss_G: 2.5589\n",
      "[118/150][5/8] Loss_D: 0.5417 Loss_G: 1.9727\n",
      "[118/150][6/8] Loss_D: 0.5461 Loss_G: 3.7025\n",
      "[118/150][7/8] Loss_D: 0.4590 Loss_G: 2.6866\n",
      "[119/150][0/8] Loss_D: 0.2635 Loss_G: 3.0528\n",
      "[119/150][1/8] Loss_D: 0.6320 Loss_G: 5.2383\n",
      "[119/150][2/8] Loss_D: 1.1025 Loss_G: 1.9070\n",
      "[119/150][3/8] Loss_D: 0.3496 Loss_G: 5.2134\n",
      "[119/150][4/8] Loss_D: 0.6522 Loss_G: 3.8706\n",
      "[119/150][5/8] Loss_D: 0.8924 Loss_G: 0.4792\n",
      "[119/150][6/8] Loss_D: 1.7439 Loss_G: 9.0006\n",
      "[119/150][7/8] Loss_D: 6.4302 Loss_G: 2.0384\n",
      "[120/150][0/8] Loss_D: 1.3206 Loss_G: 0.5997\n",
      "[120/150][1/8] Loss_D: 1.6830 Loss_G: 4.8679\n",
      "[120/150][2/8] Loss_D: 3.6785 Loss_G: 0.2622\n",
      "[120/150][3/8] Loss_D: 2.4558 Loss_G: 1.7891\n",
      "[120/150][4/8] Loss_D: 1.7828 Loss_G: 1.0361\n",
      "[120/150][5/8] Loss_D: 1.5832 Loss_G: 1.4651\n",
      "[120/150][6/8] Loss_D: 1.4822 Loss_G: 1.2133\n",
      "[120/150][7/8] Loss_D: 0.9335 Loss_G: 1.6199\n",
      "[121/150][0/8] Loss_D: 1.3841 Loss_G: 3.0030\n",
      "[121/150][1/8] Loss_D: 1.8167 Loss_G: 0.4244\n",
      "[121/150][2/8] Loss_D: 1.7966 Loss_G: 2.3650\n",
      "[121/150][3/8] Loss_D: 1.7547 Loss_G: 0.6234\n",
      "[121/150][4/8] Loss_D: 1.4200 Loss_G: 2.2404\n",
      "[121/150][5/8] Loss_D: 1.3629 Loss_G: 1.0390\n",
      "[121/150][6/8] Loss_D: 1.3877 Loss_G: 1.6588\n",
      "[121/150][7/8] Loss_D: 1.2006 Loss_G: 0.7329\n",
      "[122/150][0/8] Loss_D: 1.2713 Loss_G: 2.6598\n",
      "[122/150][1/8] Loss_D: 1.5390 Loss_G: 0.2238\n",
      "[122/150][2/8] Loss_D: 1.7949 Loss_G: 3.7954\n",
      "[122/150][3/8] Loss_D: 1.7372 Loss_G: 0.8154\n",
      "[122/150][4/8] Loss_D: 1.2950 Loss_G: 2.6540\n",
      "[122/150][5/8] Loss_D: 1.5935 Loss_G: 0.5853\n",
      "[122/150][6/8] Loss_D: 0.8806 Loss_G: 2.9156\n",
      "[122/150][7/8] Loss_D: 0.9366 Loss_G: 1.1628\n",
      "[123/150][0/8] Loss_D: 1.5480 Loss_G: 3.1767\n",
      "[123/150][1/8] Loss_D: 1.9997 Loss_G: 0.5589\n",
      "[123/150][2/8] Loss_D: 1.9194 Loss_G: 3.2591\n",
      "[123/150][3/8] Loss_D: 2.2122 Loss_G: 0.3598\n",
      "[123/150][4/8] Loss_D: 1.3804 Loss_G: 2.1736\n",
      "[123/150][5/8] Loss_D: 1.0792 Loss_G: 1.4911\n",
      "[123/150][6/8] Loss_D: 1.3333 Loss_G: 0.8633\n",
      "[123/150][7/8] Loss_D: 1.1610 Loss_G: 1.9487\n",
      "[124/150][0/8] Loss_D: 1.1389 Loss_G: 0.9007\n",
      "[124/150][1/8] Loss_D: 1.3279 Loss_G: 1.7961\n",
      "[124/150][2/8] Loss_D: 1.3506 Loss_G: 0.6745\n",
      "[124/150][3/8] Loss_D: 1.2273 Loss_G: 1.4129\n",
      "[124/150][4/8] Loss_D: 0.9742 Loss_G: 2.5838\n",
      "[124/150][5/8] Loss_D: 1.2801 Loss_G: 1.0125\n",
      "[124/150][6/8] Loss_D: 1.1286 Loss_G: 1.2062\n",
      "[124/150][7/8] Loss_D: 0.7796 Loss_G: 3.5910\n",
      "[125/150][0/8] Loss_D: 1.3986 Loss_G: 0.4271\n",
      "[125/150][1/8] Loss_D: 1.5716 Loss_G: 3.9275\n",
      "[125/150][2/8] Loss_D: 1.9858 Loss_G: 0.3014\n",
      "[125/150][3/8] Loss_D: 2.5768 Loss_G: 2.3353\n",
      "[125/150][4/8] Loss_D: 1.4778 Loss_G: 1.0035\n",
      "[125/150][5/8] Loss_D: 1.2541 Loss_G: 0.6561\n",
      "[125/150][6/8] Loss_D: 1.3889 Loss_G: 1.5284\n",
      "[125/150][7/8] Loss_D: 1.4673 Loss_G: 0.7520\n",
      "[126/150][0/8] Loss_D: 1.3469 Loss_G: 1.0782\n",
      "[126/150][1/8] Loss_D: 1.4012 Loss_G: 0.8246\n",
      "[126/150][2/8] Loss_D: 1.3447 Loss_G: 1.1641\n",
      "[126/150][3/8] Loss_D: 1.3175 Loss_G: 0.9509\n",
      "[126/150][4/8] Loss_D: 1.4319 Loss_G: 1.3244\n",
      "[126/150][5/8] Loss_D: 1.3516 Loss_G: 0.6878\n",
      "[126/150][6/8] Loss_D: 1.3781 Loss_G: 1.4303\n",
      "[126/150][7/8] Loss_D: 1.5872 Loss_G: 0.5330\n",
      "[127/150][0/8] Loss_D: 1.5371 Loss_G: 1.3240\n",
      "[127/150][1/8] Loss_D: 1.3095 Loss_G: 0.9316\n",
      "[127/150][2/8] Loss_D: 1.2075 Loss_G: 1.1718\n",
      "[127/150][3/8] Loss_D: 1.3926 Loss_G: 1.2350\n",
      "[127/150][4/8] Loss_D: 1.5424 Loss_G: 0.5240\n",
      "[127/150][5/8] Loss_D: 1.3806 Loss_G: 1.6206\n",
      "[127/150][6/8] Loss_D: 1.4204 Loss_G: 0.7439\n",
      "[127/150][7/8] Loss_D: 1.3858 Loss_G: 1.1969\n",
      "[128/150][0/8] Loss_D: 1.5317 Loss_G: 0.8431\n",
      "[128/150][1/8] Loss_D: 1.2970 Loss_G: 1.2445\n",
      "[128/150][2/8] Loss_D: 1.1398 Loss_G: 1.7773\n",
      "[128/150][3/8] Loss_D: 1.5185 Loss_G: 0.5555\n",
      "[128/150][4/8] Loss_D: 1.5324 Loss_G: 1.3462\n",
      "[128/150][5/8] Loss_D: 1.1123 Loss_G: 1.3738\n",
      "[128/150][6/8] Loss_D: 1.1826 Loss_G: 0.9359\n",
      "[128/150][7/8] Loss_D: 1.5088 Loss_G: 1.8629\n",
      "[129/150][0/8] Loss_D: 1.5029 Loss_G: 0.5917\n",
      "[129/150][1/8] Loss_D: 1.4185 Loss_G: 2.3673\n",
      "[129/150][2/8] Loss_D: 1.7557 Loss_G: 0.5675\n",
      "[129/150][3/8] Loss_D: 1.5754 Loss_G: 2.2485\n",
      "[129/150][4/8] Loss_D: 1.1453 Loss_G: 1.2847\n",
      "[129/150][5/8] Loss_D: 1.1359 Loss_G: 2.3935\n",
      "[129/150][6/8] Loss_D: 1.7243 Loss_G: 0.7992\n",
      "[129/150][7/8] Loss_D: 1.1923 Loss_G: 1.8407\n",
      "[130/150][0/8] Loss_D: 1.1820 Loss_G: 3.4689\n",
      "[130/150][1/8] Loss_D: 1.9578 Loss_G: 0.6288\n",
      "[130/150][2/8] Loss_D: 1.1160 Loss_G: 2.1754\n",
      "[130/150][3/8] Loss_D: 0.8587 Loss_G: 2.8018\n",
      "[130/150][4/8] Loss_D: 1.2379 Loss_G: 1.2594\n",
      "[130/150][5/8] Loss_D: 1.9849 Loss_G: 3.8168\n",
      "[130/150][6/8] Loss_D: 2.7606 Loss_G: 1.4206\n",
      "[130/150][7/8] Loss_D: 0.6599 Loss_G: 2.6986\n",
      "[131/150][0/8] Loss_D: 1.0940 Loss_G: 3.3839\n",
      "[131/150][1/8] Loss_D: 2.3653 Loss_G: 0.8882\n",
      "[131/150][2/8] Loss_D: 1.4907 Loss_G: 2.6881\n",
      "[131/150][3/8] Loss_D: 1.3747 Loss_G: 0.7323\n",
      "[131/150][4/8] Loss_D: 1.4237 Loss_G: 0.6368\n",
      "[131/150][5/8] Loss_D: 1.7583 Loss_G: 2.7724\n",
      "[131/150][6/8] Loss_D: 1.4977 Loss_G: 0.9389\n",
      "[131/150][7/8] Loss_D: 1.0104 Loss_G: 0.9204\n",
      "[132/150][0/8] Loss_D: 1.6187 Loss_G: 2.0201\n",
      "[132/150][1/8] Loss_D: 1.1816 Loss_G: 0.9967\n",
      "[132/150][2/8] Loss_D: 1.1671 Loss_G: 1.5575\n",
      "[132/150][3/8] Loss_D: 1.0052 Loss_G: 1.8355\n",
      "[132/150][4/8] Loss_D: 1.1728 Loss_G: 0.8358\n",
      "[132/150][5/8] Loss_D: 1.3253 Loss_G: 3.4776\n",
      "[132/150][6/8] Loss_D: 1.8939 Loss_G: 0.5653\n",
      "[132/150][7/8] Loss_D: 0.8664 Loss_G: 1.9587\n",
      "[133/150][0/8] Loss_D: 0.7975 Loss_G: 2.0660\n",
      "[133/150][1/8] Loss_D: 1.0714 Loss_G: 1.2878\n",
      "[133/150][2/8] Loss_D: 0.8383 Loss_G: 2.5309\n",
      "[133/150][3/8] Loss_D: 0.5265 Loss_G: 3.1737\n",
      "[133/150][4/8] Loss_D: 0.9997 Loss_G: 2.1311\n",
      "[133/150][5/8] Loss_D: 0.6562 Loss_G: 1.9567\n",
      "[133/150][6/8] Loss_D: 0.4321 Loss_G: 2.7999\n",
      "[133/150][7/8] Loss_D: 0.6359 Loss_G: 1.3102\n",
      "[134/150][0/8] Loss_D: 0.9593 Loss_G: 4.5305\n",
      "[134/150][1/8] Loss_D: 1.6387 Loss_G: 0.1254\n",
      "[134/150][2/8] Loss_D: 1.8690 Loss_G: 5.5286\n",
      "[134/150][3/8] Loss_D: 3.9547 Loss_G: 0.3862\n",
      "[134/150][4/8] Loss_D: 1.4601 Loss_G: 2.6277\n",
      "[134/150][5/8] Loss_D: 2.1648 Loss_G: 0.3497\n",
      "[134/150][6/8] Loss_D: 1.9198 Loss_G: 2.0266\n",
      "[134/150][7/8] Loss_D: 1.6822 Loss_G: 0.7602\n",
      "[135/150][0/8] Loss_D: 1.3915 Loss_G: 1.1142\n",
      "[135/150][1/8] Loss_D: 1.4607 Loss_G: 1.0837\n",
      "[135/150][2/8] Loss_D: 1.4234 Loss_G: 0.7715\n",
      "[135/150][3/8] Loss_D: 1.3094 Loss_G: 1.6851\n",
      "[135/150][4/8] Loss_D: 1.2669 Loss_G: 1.1492\n",
      "[135/150][5/8] Loss_D: 1.3526 Loss_G: 0.8763\n",
      "[135/150][6/8] Loss_D: 1.2009 Loss_G: 1.3529\n",
      "[135/150][7/8] Loss_D: 1.2110 Loss_G: 1.3460\n",
      "[136/150][0/8] Loss_D: 1.2490 Loss_G: 0.9116\n",
      "[136/150][1/8] Loss_D: 1.4353 Loss_G: 2.3808\n",
      "[136/150][2/8] Loss_D: 1.5355 Loss_G: 0.4246\n",
      "[136/150][3/8] Loss_D: 1.4806 Loss_G: 2.3569\n",
      "[136/150][4/8] Loss_D: 1.6689 Loss_G: 0.4252\n",
      "[136/150][5/8] Loss_D: 1.4701 Loss_G: 2.4180\n",
      "[136/150][6/8] Loss_D: 1.6571 Loss_G: 0.5069\n",
      "[136/150][7/8] Loss_D: 1.5688 Loss_G: 1.7818\n",
      "[137/150][0/8] Loss_D: 1.5810 Loss_G: 0.7023\n",
      "[137/150][1/8] Loss_D: 1.4839 Loss_G: 2.2590\n",
      "[137/150][2/8] Loss_D: 1.7081 Loss_G: 1.0734\n",
      "[137/150][3/8] Loss_D: 1.2712 Loss_G: 0.7411\n",
      "[137/150][4/8] Loss_D: 1.5292 Loss_G: 1.7272\n",
      "[137/150][5/8] Loss_D: 1.5057 Loss_G: 0.6113\n",
      "[137/150][6/8] Loss_D: 1.4588 Loss_G: 1.1844\n",
      "[137/150][7/8] Loss_D: 1.3451 Loss_G: 0.8556\n",
      "[138/150][0/8] Loss_D: 1.5330 Loss_G: 1.5165\n",
      "[138/150][1/8] Loss_D: 1.4174 Loss_G: 0.6942\n",
      "[138/150][2/8] Loss_D: 1.1356 Loss_G: 1.6324\n",
      "[138/150][3/8] Loss_D: 1.3005 Loss_G: 1.0576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[138/150][4/8] Loss_D: 1.4115 Loss_G: 0.8993\n",
      "[138/150][5/8] Loss_D: 1.4449 Loss_G: 1.6989\n",
      "[138/150][6/8] Loss_D: 1.3558 Loss_G: 0.6243\n",
      "[138/150][7/8] Loss_D: 1.0716 Loss_G: 2.3004\n",
      "[139/150][0/8] Loss_D: 1.4209 Loss_G: 0.6471\n",
      "[139/150][1/8] Loss_D: 1.5336 Loss_G: 1.8803\n",
      "[139/150][2/8] Loss_D: 1.3381 Loss_G: 0.9423\n",
      "[139/150][3/8] Loss_D: 1.3145 Loss_G: 2.3614\n",
      "[139/150][4/8] Loss_D: 1.3989 Loss_G: 0.6650\n",
      "[139/150][5/8] Loss_D: 1.2470 Loss_G: 1.6937\n",
      "[139/150][6/8] Loss_D: 1.2660 Loss_G: 1.3413\n",
      "[139/150][7/8] Loss_D: 1.0437 Loss_G: 1.5941\n",
      "[140/150][0/8] Loss_D: 1.1400 Loss_G: 1.4009\n",
      "[140/150][1/8] Loss_D: 0.9840 Loss_G: 2.3730\n",
      "[140/150][2/8] Loss_D: 2.0306 Loss_G: 1.0871\n",
      "[140/150][3/8] Loss_D: 1.0882 Loss_G: 2.5700\n",
      "[140/150][4/8] Loss_D: 1.5286 Loss_G: 0.4440\n",
      "[140/150][5/8] Loss_D: 1.5146 Loss_G: 2.8577\n",
      "[140/150][6/8] Loss_D: 1.6639 Loss_G: 0.9265\n",
      "[140/150][7/8] Loss_D: 0.9310 Loss_G: 1.9175\n",
      "[141/150][0/8] Loss_D: 1.0395 Loss_G: 2.2852\n",
      "[141/150][1/8] Loss_D: 1.2423 Loss_G: 1.3604\n",
      "[141/150][2/8] Loss_D: 0.8905 Loss_G: 2.1070\n",
      "[141/150][3/8] Loss_D: 1.4363 Loss_G: 2.8367\n",
      "[141/150][4/8] Loss_D: 2.0875 Loss_G: 0.2451\n",
      "[141/150][5/8] Loss_D: 1.7044 Loss_G: 3.3851\n",
      "[141/150][6/8] Loss_D: 2.1267 Loss_G: 0.6799\n",
      "[141/150][7/8] Loss_D: 1.4903 Loss_G: 1.3276\n",
      "[142/150][0/8] Loss_D: 0.9708 Loss_G: 1.6236\n",
      "[142/150][1/8] Loss_D: 1.1450 Loss_G: 1.4507\n",
      "[142/150][2/8] Loss_D: 1.6504 Loss_G: 1.4279\n",
      "[142/150][3/8] Loss_D: 1.4984 Loss_G: 0.7820\n",
      "[142/150][4/8] Loss_D: 1.2700 Loss_G: 3.2459\n",
      "[142/150][5/8] Loss_D: 1.4537 Loss_G: 0.6474\n",
      "[142/150][6/8] Loss_D: 2.1486 Loss_G: 3.1246\n",
      "[142/150][7/8] Loss_D: 1.7429 Loss_G: 1.2197\n",
      "[143/150][0/8] Loss_D: 1.0963 Loss_G: 1.6060\n",
      "[143/150][1/8] Loss_D: 1.4585 Loss_G: 1.5362\n",
      "[143/150][2/8] Loss_D: 1.3952 Loss_G: 1.1853\n",
      "[143/150][3/8] Loss_D: 1.4629 Loss_G: 2.4488\n",
      "[143/150][4/8] Loss_D: 1.5004 Loss_G: 0.8883\n",
      "[143/150][5/8] Loss_D: 1.0202 Loss_G: 1.6774\n",
      "[143/150][6/8] Loss_D: 1.1547 Loss_G: 2.4800\n",
      "[143/150][7/8] Loss_D: 1.4903 Loss_G: 0.5857\n",
      "[144/150][0/8] Loss_D: 1.4269 Loss_G: 2.9761\n",
      "[144/150][1/8] Loss_D: 1.1030 Loss_G: 2.0625\n",
      "[144/150][2/8] Loss_D: 1.3277 Loss_G: 0.9883\n",
      "[144/150][3/8] Loss_D: 1.0478 Loss_G: 2.8393\n",
      "[144/150][4/8] Loss_D: 1.2404 Loss_G: 1.5882\n",
      "[144/150][5/8] Loss_D: 1.1678 Loss_G: 0.8981\n",
      "[144/150][6/8] Loss_D: 0.9764 Loss_G: 3.5189\n",
      "[144/150][7/8] Loss_D: 0.7348 Loss_G: 2.7432\n",
      "[145/150][0/8] Loss_D: 0.8969 Loss_G: 1.3065\n",
      "[145/150][1/8] Loss_D: 0.4950 Loss_G: 2.7839\n",
      "[145/150][2/8] Loss_D: 0.4144 Loss_G: 2.4631\n",
      "[145/150][3/8] Loss_D: 0.6889 Loss_G: 2.3986\n",
      "[145/150][4/8] Loss_D: 1.4541 Loss_G: 3.4650\n",
      "[145/150][5/8] Loss_D: 3.0696 Loss_G: 1.4592\n",
      "[145/150][6/8] Loss_D: 1.1852 Loss_G: 3.9139\n",
      "[145/150][7/8] Loss_D: 0.8140 Loss_G: 4.5425\n",
      "[146/150][0/8] Loss_D: 2.7881 Loss_G: 0.8374\n",
      "[146/150][1/8] Loss_D: 0.5531 Loss_G: 2.7372\n",
      "[146/150][2/8] Loss_D: 0.3788 Loss_G: 2.9265\n",
      "[146/150][3/8] Loss_D: 0.7734 Loss_G: 2.7013\n",
      "[146/150][4/8] Loss_D: 1.3611 Loss_G: 0.9529\n",
      "[146/150][5/8] Loss_D: 0.7171 Loss_G: 4.1275\n",
      "[146/150][6/8] Loss_D: 0.7708 Loss_G: 1.7995\n",
      "[146/150][7/8] Loss_D: 0.9435 Loss_G: 3.1921\n",
      "[147/150][0/8] Loss_D: 2.0245 Loss_G: 0.3081\n",
      "[147/150][1/8] Loss_D: 1.5354 Loss_G: 4.5521\n",
      "[147/150][2/8] Loss_D: 2.5725 Loss_G: 0.8372\n",
      "[147/150][3/8] Loss_D: 1.2438 Loss_G: 2.1394\n",
      "[147/150][4/8] Loss_D: 1.2659 Loss_G: 2.5164\n",
      "[147/150][5/8] Loss_D: 2.0041 Loss_G: 0.3012\n",
      "[147/150][6/8] Loss_D: 1.9067 Loss_G: 2.6522\n",
      "[147/150][7/8] Loss_D: 1.6356 Loss_G: 0.8725\n",
      "[148/150][0/8] Loss_D: 1.1785 Loss_G: 1.2243\n",
      "[148/150][1/8] Loss_D: 1.1314 Loss_G: 1.3455\n",
      "[148/150][2/8] Loss_D: 1.2925 Loss_G: 0.7820\n",
      "[148/150][3/8] Loss_D: 1.3152 Loss_G: 1.7922\n",
      "[148/150][4/8] Loss_D: 1.5361 Loss_G: 0.6373\n",
      "[148/150][5/8] Loss_D: 1.2177 Loss_G: 2.1333\n",
      "[148/150][6/8] Loss_D: 0.9731 Loss_G: 0.8968\n",
      "[148/150][7/8] Loss_D: 1.2618 Loss_G: 2.6970\n",
      "[149/150][0/8] Loss_D: 1.2639 Loss_G: 1.2500\n",
      "[149/150][1/8] Loss_D: 1.2381 Loss_G: 3.1075\n",
      "[149/150][2/8] Loss_D: 1.4562 Loss_G: 0.8579\n",
      "[149/150][3/8] Loss_D: 1.1405 Loss_G: 5.1575\n",
      "[149/150][4/8] Loss_D: 2.7549 Loss_G: 0.1834\n",
      "[149/150][5/8] Loss_D: 1.5514 Loss_G: 2.9704\n",
      "[149/150][6/8] Loss_D: 1.6183 Loss_G: 0.6218\n",
      "[149/150][7/8] Loss_D: 1.4359 Loss_G: 1.9981\n",
      "Training Completed\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dsets \n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#hyperparameters\n",
    "batchsize=64 #batch-size of 64\n",
    "imgsize=64 #image of size (64,64)\n",
    "\n",
    "#creating transformations so that the image is ready to be fed to the neural network\n",
    "transform=transforms.Compose([transforms.Resize(imgsize),transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]) # Applying transformation(resizing,tensor conversion and normalization) to the image  \n",
    "\n",
    "#loading the dataset\n",
    "dataset=dsets.ImageFolder(root='mydata',transform=transform)\n",
    "dataloader=torch.utils.data.DataLoader(dataset,batch_size=batchsize,shuffle=True,num_workers=3) #Dataloader helps is to load data in specific batch size and whether we want to shuffle it or not and num_workers=-1 means it uses all the parallel processes available\n",
    "\n",
    "print('Dataloader executed')\n",
    "#GANs use a different type of weight initialization called Xavier's Initialization\n",
    "def weights(network):\n",
    "\tclassname=network.__class__.__name__ # this line searches for the name of the class in the network defination\n",
    "\tif classname.find('Conv') !=-1: #this line finds the occurance of the strin g 'Conv' in the network function's defination and if the string 'Conv' is present then it activates the if loop\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tnetwork.weight.normal_(0.0,0.02)\n",
    "\telif classname.find('BatchNorm')!=-1: #similar operation as above\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tnetwork.weight.data.normal_(1.0,0.02)\n",
    "\t\t# network.bias.data.fill_(0)\n",
    "# Defining the generator network\n",
    "\n",
    "class generator(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(generator,self).__init__() # this line passes all the goodness of nn.module in the generator class that we defined \n",
    "\t\tself.main=nn.Sequential(nn.ConvTranspose2d(100,512,4,1,0,bias=False), #100 is the input noise vector, 512 are the new feature maps,4 is the size of kernel(4,4),1 is the stride of the kernel,0 is the padding and bias is set to false\n",
    "\t\t\tnn.ReLU(True), #to introduce non-linearity\n",
    "\t\t\tnn.BatchNorm2d(512), #normalizing all the new feature maps\n",
    "\t\t\tnn.ConvTranspose2d(512,256,4,2,1,bias=False),\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t\tnn.BatchNorm2d(256),\n",
    "\t\t\tnn.ConvTranspose2d(256,128,4,2,1,bias=False),\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t\tnn.BatchNorm2d(128),\n",
    "\t\t\tnn.ConvTranspose2d(128,64,4,2,1,bias=False),\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t\tnn.BatchNorm2d(64),\n",
    "\t\t\tnn.ConvTranspose2d(64,3,4,2,1,bias=False),\n",
    "\t\t\tnn.Tanh() #Tanh is selected here because the dataset has values between -1 and 1 , also Tanh is bounded, this bounded and symmetrical nature of the function helps the model to learn faster \n",
    "\t\t\t)\n",
    "\tdef forward(self,x):\n",
    "\t\toutput=self.main(x)\n",
    "\t\treturn output\n",
    "netG=generator()\n",
    "netG.cuda()\n",
    "netG.apply(weights) #applying weights initizlization function on the generator function\n",
    "\n",
    "\n",
    "class discriminator(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(discriminator,self).__init__() #to activate inheritance\n",
    "\t\tself.main=nn.Sequential(\n",
    "\t\t\tnn.Conv2d(3,64,4,2,1,bias=False),\n",
    "\t\t\tnn.LeakyReLU(0.02,inplace=True),\n",
    "\t\t\tnn.Conv2d(64,128,4,2,1,bias=False),\n",
    "\t\t\tnn.BatchNorm2d(128),\n",
    "\t\t\tnn.LeakyReLU(0.02,inplace=True),\n",
    "\t\t\tnn.Conv2d(128,256,4,2,1,bias=False),\n",
    "\t\t\tnn.BatchNorm2d(256),\n",
    "\t\t\tnn.LeakyReLU(0.02,inplace=True),\n",
    "\t\t\tnn.Conv2d(256,512,4,2,1,bias=False),\n",
    "\t\t\tnn.BatchNorm2d(512),\n",
    "\t\t\tnn.LeakyReLU(0.02,inplace=True),\n",
    "\t\t\tnn.Conv2d(512,1,4,1,0,bias=False),\n",
    "\t\t\tnn.Sigmoid()\n",
    "\t\t\t)\n",
    "\tdef forward(self,x):\n",
    "\t\toutput=self.main(x)\n",
    "\t\treturn output.view(-1) # .view(-1) is used to reshape the convouled image and flatten it along a single axis.\n",
    "\n",
    "print('Networks defined')\n",
    "netD=discriminator()\n",
    "netD.cuda()\n",
    "netD.apply(weights) #applying weights initizlization function on the generator function\n",
    "\n",
    "run=150 ### number of epochs\n",
    "\n",
    "\n",
    "\n",
    "###### TRAINING THE GANs ########\n",
    "criterion = nn.BCELoss()\n",
    "optimizerD=optim.Adam(netD.parameters(),lr=0.001,betas=(0.5,0.999)) #the value of betas is selected from experimentation\n",
    "optimizerG=optim.Adam(netG.parameters(),lr=0.001,betas=(0.5,0.999))\n",
    "err_dis=[]\n",
    "err_gen=[]\n",
    "print('Loop starting now')\n",
    "for epoch in range(run):\t\n",
    "\tfor i,data in enumerate(dataloader,0): #0 in the enumerate parenthesis is just the starting value we want 'i' to take.\n",
    "\t\tnetD.zero_grad() #clearing gradient buffers and setting it to zero for every new batch\n",
    "\n",
    "\n",
    "\n",
    "\t\t###Training the discriminator network on real images\n",
    "\n",
    "\t\timages,_=data #_ here holds the labels of the images. As we dont want the labels here we just throw it away\n",
    "\t\treal=Variable(images.cuda()) #to compute gradients, we need to wrap the image with a Variable class\n",
    "\t\treal_targets=Variable(torch.ones(real.size()[0]).cuda()) #setting real tagerts to 1s and deciding the size on basis of how many images are present in real variable\n",
    "\t\toutput=netD(real) #computing the outputs through discriminator which will be a number between 0 and 1 giving probablity of image being real or fake\n",
    "\t\terror_real=criterion(output,real_targets) #calculating the error for real images and their output given by our discriminator network\n",
    "\n",
    "\t\t###Training the images on fake network\n",
    "\t\tnoise=Variable(torch.randn(real.size()[0],100,1,1).cuda()) #this line can be interpreted like a matrix which has real.size()[0] number of rows and 100 number of columns(technically feature maps) and each column has a 1x1 array\n",
    "\t\tfake_output=netG(noise)  #generator uses this noise vector to generate a mini-batch of fakeimages\n",
    "\t\tfake_target=Variable(torch.zeros(real.size()[0]).cuda())#instantiating the fake target as 0s\n",
    "\t\toutput=netD(fake_output.detach()) #the fake_output is a torch variable and it contains the data as well as the gradients, but we dont want this gradients so we will only use the data and for that we use .detach() method\n",
    "\t\terror_fake=criterion(output,fake_target) #calculating the error of fake images with wrt their output\n",
    "\n",
    "\t\terror_total=error_real+error_fake\n",
    "\t\terror_total.backward() #this line back-propagates the error \n",
    "\t\toptimizerD.step()      #this line updates the parameters of netD\n",
    "\n",
    "\t\t##Training the generator\n",
    "\t\tnetG.zero_grad() #initializing the gradients of generaotr neural net\n",
    "\t\toutput=netD(fake_output) #notice here we didnt use .detach() because we want to update the weights of generator unlike previously where we were updating the weights of discriminator, because the fake_output is generated by generator and not discriminator\n",
    "\t\ttarget=Variable(torch.ones(real.size()[0]).cuda()) #here we defined targets as 1s because we want the generator to generate near perfect images which the discriminator should predict as real( or target =1) \n",
    "\t\terror_gen=criterion(output,target)\n",
    "\t\terror_gen.backward()\n",
    "\t\toptimizerG.step()\n",
    "\t\tprint('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f' % (epoch, run, i, len(dataloader), error_total.data, error_gen.data))\n",
    "\t\tif i%10000==0:\n",
    "\t\t\tvutils.save_image(real, '%s/real_samples.png' % \"./results\", normalize = True)\n",
    "\t\t\tfake = netG(noise)\n",
    "\t\t\tvutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png' % (\"./results\", epoch), normalize = True)\n",
    "\terr_dis.append(torch.sum(error_total))\n",
    "\terr_gen.append(torch.sum(error_gen))\n",
    "\n",
    "print('Training Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(run),err_dis,label='Discriminator')\n",
    "plt.plot(range(run),err_gen,label='Generator')\n",
    "plt.legend()\n",
    "plt.title('Training Losses')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.savefig('loss_trend.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DHARMIK\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:250: UserWarning: Couldn't retrieve source code for container of type discriminator. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\DHARMIK\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:250: UserWarning: Couldn't retrieve source code for container of type generator. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(netD,'Discriminator network')\n",
    "torch.save(netG,'Generator network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=torch.load('Discriminator network') #use this line to save model in variable 'a'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
